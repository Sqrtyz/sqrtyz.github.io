<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://sqrtyz.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sqrtyz.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-30T04:27:25+00:00</updated><id>https://sqrtyz.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Computer Organization Note (Part 1 of 4)</title><link href="https://sqrtyz.github.io/blog/2024/CO-NOTE-1/" rel="alternate" type="text/html" title="Computer Organization Note (Part 1 of 4)"/><published>2024-01-01T12:00:00+00:00</published><updated>2024-01-01T12:00:00+00:00</updated><id>https://sqrtyz.github.io/blog/2024/CO-NOTE-1</id><content type="html" xml:base="https://sqrtyz.github.io/blog/2024/CO-NOTE-1/"><![CDATA[<blockquote> <p>Part I 包含第一、三章，涉及导论内容和计算机运算问题。</p> </blockquote> <h2 id="chapter-1-computer-abstractions-and-technology">Chapter 1. Computer Abstractions and Technology</h2> <h3 id="history--development">History &amp; Development</h3> <ul> <li>第一代：电子管 / 真空管</li> <li>第二代：晶体管</li> <li>第三代：集成电路</li> <li>第四代：微处理器</li> </ul> <h3 id="computer-organization">Computer Organization</h3> <ul> <li> <p>Hardware</p> <p><img src="/assets/img/blog_post/co/cod-3.png" alt="cod-3" width="50%"/></p> <p>Datapath 可以理解为一条「流水线」。</p> </li> <li> <p>Software</p> <p><img src="/assets/img/blog_post/co/cod-4.png" alt="cod-4" width="50%"/></p> </li> </ul> <h3 id="指令集isa">指令集（ISA）</h3> <ul> <li> <p><strong>ISA</strong>: The interface between hardware and lowest-level software.</p> <p>指令集筑起了「硬件」与「软件」之间的桥梁。硬件生产厂商只需要支持指令集中的特定操作，而软件厂商只需要借助这些基本指令集来开发软件。</p> </li> </ul> <h3 id="cpu-time-calculation">CPU Time Calculation</h3> <ul> <li> <p>Basic Concepts</p> <ul> <li> <p><strong>[CONCEPT] Response Time</strong> (Execution Time)：响应时间，how long it takes to do a task.</p> </li> <li> <p><strong>[CONCEPT] Throughput</strong> (Bandwidth)：吞吐率，total work done per unit time.</p> </li> </ul> </li> <li> <p>Performance Measurement</p> <p>假设 X 比 Y 快 $n$ 倍，那么 $\frac{\text{Execution Time}_Y}{\text{Execution Time}_X}=n$。</p> </li> <li> <p>Clock</p> <p><img src="/assets/img/blog_post/co/cod-5.png" alt="cod-5" width="50%"/></p> <ul> <li> <p><strong>[CONCEPT] Clock Cycle Time</strong>: duration of a clock cycle.</p> </li> <li> <p><strong>[CONCEPT] Clock Rate</strong>: cycles per second，与 Clock period 成倒数。</p> </li> <li> <p>CPU Time = CPU Clock Cycles × Clock Cycle Time = CPU Clock Cycles / Clock Rate</p> </li> </ul> </li> <li> <p>Considering Instructions</p> <ul> <li> <p><strong>[CONCEPT] CPI</strong>: Cycles Per Instruction. <strong>CPI 的值由 CPU 本身决定，同时也受到指令种类的影响</strong>（例如，加法和乘法所需要的 Cycles 肯定不一样）。</p> </li> <li> <p>Clock Cycles = Instruction Count × CPI</p> <p>CPU Time = Instruction Count × CPI × Clock Cycle Time = Instruction Count × CPI / Clock Rate</p> </li> <li> <p>考虑不同 Instruction Type 对 CPI 的影响……</p> <p>$\text{Clock Cycles} = \sum\limits_{i=1}^n (\text{CPI}_i \times \text{Instruction Count}_i)$</p> <p>加权平均 CPI（global CPI）：字面意思。</p> </li> </ul> </li> <li> <p>Power Spent</p> <p>$\text{Power} = \text{Capacitive load}^2 \times \text{Voltage} \times \text{Frequency}$</p> </li> <li> <p>习题演示</p> <p><img src="/assets/img/blog_post/co/cod-6.png" alt="cod-6" width="50%"/></p> </li> </ul> <h3 id="some-pitfalls--fallacies">Some Pitfalls / Fallacies</h3> <ul> <li> <p>Amdahl’s Law 提升局部不一定能提升总体</p> \[T_{imporved} = \frac{T_{affected}}{\text{improvement factor}} + T_{unaffected}\] <p>其中 $T_{imporved}$ 表示提升后的总用时。$\text{improvement factor}$ 表示受影响的提升方面的提升比例。此公式意在说明，对于某种提升，只有 affected 的部分会变快，unaffected 的部分怎么都不会变快。</p> <p>例如，一个程序需要执行 80s 的乘法和 20s 的除法。无论乘法提升了多少，我们都无法把总时间提升 5 倍。</p> </li> <li> <p>Low Power at Idle 功耗和负载不成正比</p> <p>对于 i7 power benchmark，100% 负载下的功耗为 258W，50% 负载下为 170W，10% 负载下为 121W。也就是说，一味降低 CPU 的负载不一定能起到节能的效果。</p> </li> <li> <p>MIPS as a Performance Metric? MIPS 是否能作为衡量 CPU 运行速度的参数？</p> <p>MIPS: Millions of Instructions Per Second</p> \[\text{MIPS} = \frac{\text{Clock Rate}}{\text{CPI} \times 10^6}\] <p>之前提及，CPI 除了受 CPU 本身的影响，也受到 CPI 种类等因素的影响。不同电脑的指令集架构不同，进而导致 CPI 不同；同时，不同指令的 CPI 也不一样。所以 MIPS 并非一个只和 CPU 本身有关的量。所以用 MIPS 来衡量 CPU 的运行速度是不合理的。</p> </li> </ul> <h3 id="eight-great-ideas">Eight Great Ideas</h3> <ul> <li> <p>Design for Moore’s Law (设计紧跟摩尔定律)</p> </li> <li> <p>Use Abstraction to Simplify Design (采用抽象简化设计)</p> </li> <li> <p>Make the Common Case Fast (加速大概率事件)</p> </li> <li> <p>Performance via Parallelism (通过并行提高性能)</p> </li> <li> <p>Performance via Pipelining (通过流水线提高性能)</p> </li> <li> <p>Performance via Prediction (通过预测提高性能)</p> </li> <li> <p>Hierarchy of Memories (存储器层次)</p> </li> <li> <p>Dependability via Redundancy (通过冗余提高可靠性)</p> </li> </ul> <hr/> <ul> <li> <p>Some illustrations:</p> <p>Use Abstraction to Simplify Design:</p> <p><img src="/assets/img/blog_post/co/cod-1.png" alt="cod-1" width="50%"/></p> <p>Performance via Pipelining:</p> <p><img src="/assets/img/blog_post/co/cod-2.png" alt="cod-2" width="50%"/></p> </li> </ul> <h2 id="chapter-3-arithmetic-for-computer">Chapter 3. Arithmetic for Computer</h2> <h3 id="signed-numbers-representations">Signed Numbers Representations</h3> <table> <thead> <tr> <th>Binary</th> <th>Signed Magnitude</th> <th>2’s Complement</th> </tr> </thead> <tbody> <tr> <td>000</td> <td>+0</td> <td>+0</td> </tr> <tr> <td>001</td> <td>+1</td> <td>+1</td> </tr> <tr> <td>010</td> <td>+2</td> <td>+2</td> </tr> <tr> <td>011</td> <td>+3</td> <td>+3</td> </tr> <tr> <td>100</td> <td>-0</td> <td>-4</td> </tr> <tr> <td>101</td> <td>-1</td> <td>-3</td> </tr> <tr> <td>110</td> <td>-2</td> <td>-2</td> </tr> <tr> <td>111</td> <td>-3</td> <td>-1</td> </tr> </tbody> </table> <p>一般采取补码的表示方式。</p> <h3 id="addition-and-subtraction">Addition and Subtraction</h3> <p>减法可以改成加补码。这样加和减都统一成了加法。</p> <p>加减法都可能产生 overflow。例如：</p> <p><img src="/assets/img/blog_post/co/cod-7.png" alt="cod-7" width="50%"/></p> <p>overflow 的判定遵循下表：</p> <p><img src="/assets/img/blog_post/co/cod-8.png" alt="cod-8" width="50%"/></p> <ul> <li> <p>此处的 overflow 专指「溢出导致错误的计算结果」。例如 $(-1)+(-1)=(-2)$ 我们不认为发生了 overflow。</p> </li> <li> <p>只有以上四种 A, B 组合才可能产生 overflow。例如一个正数加一个负数是不可能产生 overflow 的。</p> </li> <li> <p>Result overflow 括号中的两个数分别表示「溢出位」和「最高位」。例如 $7+7=(0111)_2+(0111)_2=(1110)_2=-2$，其溢出位（第 4 位）为 $0$，最高位（第 3 位）为 $1$，属于表中的第一行情况。</p> </li> <li> <p>可以看到「溢出位」和「最高位」在溢出情况下总是相反的，这意味着我们可以使用 XOR 门进行判定。</p> </li> </ul> <h3 id="alu">ALU</h3> <p>考虑建立具有如下功能的 ALU：</p> <p><img src="/assets/img/blog_post/co/cod-9.png" alt="cod-9" width="50%"/></p> <p>其中 srl 表示 shift right logical，Zero 位宽为 1，输出 1 当且仅当 Result 为 0。</p> <ol> <li> <p>And 与 Or</p> <p><img src="/assets/img/blog_post/co/cod-10.png" alt="cod-10" width="50%"/></p> </li> <li> <p>Add</p> <p>全加器，$S=a \oplus b \oplus C_{in}, \ C_{out}=ab+aC_{in}+bC_{in}$。</p> <p><img src="/assets/img/blog_post/co/cod-11.png" alt="cod-11" width="50%"/></p> </li> <li> <p>Sub</p> <p>减法就是加上补码。考虑 And / Or / Add / Sub 的 ALU 设计如下：</p> <p><img src="/assets/img/blog_post/co/cod-12.png" alt="cod-12" width="50%"/></p> </li> <li> <p>Set on less than (Comparison)</p> <p>用于比较输入项 $a,b$ 的大小，如果 $a &lt; b$，那么输出 $1$，反之输出 $0$。</p> <p>实现方法是执行减法运算，看最高位（符号位）是否为 $1$ 即可。</p> </li> </ol> <p>考虑 And / Or / Add / Sub / Set on less than 的 ALU 设计如下：</p> <p><img src="/assets/img/blog_post/co/cod-13.png" alt="cod-13" width="50%"/></p> <p>其中 MSB 的设计有略微不同（加入了溢出检测模块，输出 Set 和 Overflow 信号）</p> <p><img src="/assets/img/blog_post/co/cod-14.png" alt="cod-14" width="50%"/></p> <p><strong>最后我们考虑建立整个 ALU。</strong></p> <p><img src="/assets/img/blog_post/co/cod-15.png" alt="cod-15" width="50%"/></p> <p>注意到 MSB 的 Set 连到了 LSB 的 Less 输入，用于执行 Comparison 运算；非 LSB 的 Less 输入均为零。</p> <h3 id="fast-adder">Fast Adder</h3> <p><strong>Carry Lookahead Adder (CLA) 加速运算</strong>：本质上是把行波加法给「压缩」了。但受到 fan-in of gate 的影响，只有分组「压缩」。</p> <p>此部分数逻已经学过，在此不再赘述。</p> <h3 id="multiplication">Multiplication</h3> <p><strong>名词</strong>：被乘数（multiplicand），乘数（multiplier），积（product）。</p> <ol> <li> <p>Multiplier Ver 1</p> <p>Look at current bit position.</p> <ul> <li> <p>if multiplier is 1, then add multiplicand.</p> </li> <li> <p>Otherwise add 0.</p> </li> <li> <p>Shift multiplicand left by 1 bit.</p> </li> </ul> <p><img src="/assets/img/blog_post/co/cod-16.png" alt="cod-16" width="50%"/></p> <p>其实就是模拟的竖式乘法。对于两个 64 bits 的整数相乘，需要 128 bits 的寄存器存储积，同时也需要一个 128 bits 的 ALU 来执行加法。</p> </li> <li> <p>Multiplier Ver 2</p> <p>在第一版乘法器的基础上，第二版将「左移 multiplicand」改成了「右移 product」来减小 ALU 的开销。原理图和举例图如下。</p> <p><img src="/assets/img/blog_post/co/cod-17.png" alt="cod-17" width="50%"/></p> <p><img src="/assets/img/blog_post/co/cod-18.png" alt="cod-18" width="50%"/></p> <p>注意每一次是将 multiplicand 加到 product 左边的 64 位，而后进行不断的右移。对于两个 64 bits 的整数相乘，需要 128 bits 的寄存器存储积，但只需要一个 64 bits 的 ALU 来执行加法。</p> </li> <li> <p>Multiplier Ver 3</p> <p>基于第二版乘法器进行了一点小优化。回顾我们使用的 128 位的存储积的 reg，刚开始 reg 的右 64 位是空的，这意味着说我们可以将其用于存储 multiplier。并且随着后续 product 和 multiplier 的右移，两者也不会产生空间上的冲突。</p> <p><img src="/assets/img/blog_post/co/cod-19.png" alt="cod-19" width="50%"/></p> <p><img src="/assets/img/blog_post/co/cod-20.png" alt="cod-20" width="50%"/></p> <p>红色部分存储的是 multiplier。可以看到 multiplier 和 product 共用一个 reg。</p> </li> <li> <p>有符号乘法</p> <p>考虑有符号整数乘法。一种基本的方法是，符号和绝对值分开考虑。符号位直接进行 XOR，随后将 MSB 设为 0（去除符号位）并执行无符号乘法，最后将符号和绝对值的积合并即可。</p> <p>此外还有一种方法：<strong>Booth’s Algorithm.</strong></p> </li> <li> <p>Booth 算法</p> <p>Booth 算法的执行基于第三版乘法器，但是做了一定的优化。<strong>Booth 算法在加速了乘法的同时，也使得有符号的乘法运算更加统一（即不需要传统方法的分类讨论）。</strong></p> <p>考虑被乘数为 $y$，乘数为 $10111100$。按照第三版乘法器的做法，会执行 $8$ 次 shift 操作和 $5$ 次 add 操作。如果我们将 $10111100$ 改写为 $2^7+2^6-2^2$，则只需要执行 $8$ 次 shift 操作和 $3$ 次 add/sub 操作（在此我们假设 shift 速度快于 add/sub）。</p> <ul> <li> <p>流程</p> <p>每次考察乘数的 0 位和 -1 位（此处 -1 位是人为补足的，初始为 0）。并按照以下表格执行操作：</p> <table> <thead> <tr> <th>bit(0) and bit(-1)</th> <th>Operations</th> </tr> </thead> <tbody> <tr> <td>$10$</td> <td>Subtract multiplicand from left half</td> </tr> <tr> <td>$11$</td> <td>No arithmetic operations, just shift right</td> </tr> <tr> <td>$01$</td> <td>Add multiplicand to left half</td> </tr> <tr> <td>$00$</td> <td>No arithmetic operations, just shift right</td> </tr> </tbody> </table> <p>此处依然是按照第三版乘法器那样将 product, multiplier 放在一起存储，且每次 shift right 都是将两者一起右移。</p> <p><strong>同时：每次右移最高位的不足不再是无脑补零，而是和原最高位一样补（即每次右移保持符号位不变）。</strong></p> </li> <li> <p>例子</p> <p><img src="/assets/img/blog_post/co/cod-22.png" alt="cod-22" width="50%"/></p> <p>注意执行的轮次数和乘数的 bit 数一致。第一轮是 10，第二轮是 01，第三轮是 10，第四轮是 11，第五轮（本来是 11）无需执行。</p> </li> <li> <p>一些粗浅的理解</p> <p><strong>关于加减法：</strong> 遇 10 则减，遇 01 则加其实比较好颅内理解。00 和 11 不干事都是为了「把锅甩给后面的高位」。</p> <p><strong>关于右移最高位补足、为何不进行第 5 轮：</strong> 首先考虑另外一个问题，为什么常规无符号乘法无法做有符号的乘法。例如，$0010 \times 1101 = 00011010$，正负得正，显然是有问题的。</p> <p>实际上问题出在位数不足。补齐后 $00000010 \times 11111101 = 11111010$ （取低 8 位）就没有问题了。</p> <p>然而把四位乘法转化为 8 bits × 8 bits 做是有点亏的，同时注意到有很多连续的 1 似乎加法也会很多。所以使用 Booth’s Algorithm。</p> <p>解答这个问题可能需要考虑 8 bits × 8 bits 的本原做法。比如在 iteration 1 中要减去被乘数，在算法中体现的是 +1110，然而实际上应该是 +11111110。这样在整体右移一位之后最高位确实应该为 1。</p> <p>为何不进行最后一轮似乎也和这个有关。像比如上图的例子，按理说最后应该再做一个 left half 的 +0010 才对，然而当我们把乘数 $1101$ 补全为 $1111 \ 1101$ 后，发现实际上这个 +0010 应该在 iter 9 执行，实际上表现出来的就是溢出了 8 bits 的范围。</p> </li> </ul> </li> </ol> <h3 id="division">Division</h3> <p><strong>名词</strong>：被除数（dividend），除数（divisor），商（quotient），余数（remainder）。</p> <ol> <li> <p>Division Introduction</p> <ul> <li> <p>除数为 0 一般交由软件判断。</p> </li> <li> <p>有符号除法一般将符号和绝对值分开讨论。</p> </li> </ul> </li> <li> <p>Division Ver 1</p> <p><img src="/assets/img/blog_post/co/cod-23.png" alt="cod-23" width="50%"/></p> <p>假设 dividend 和 divisor 都是 64 位的。</p> <ul> <li> <p>首先将实际的 divisor 放到高 64 位（低 64 位为零）。remainder 初始设置为 dividend。</p> </li> <li> <p>接下来每次拿 remainder 减去 divisor。若减后 remainder 大于等于 0，则将 quotient 左移并将 LSB 设为 1；若减后 remainder 小于 0，则恢复原值（把 divisor 加回去），同时也将 quotient 左移。</p> </li> <li> <p>将 divisor 右移一位。重复 65 次。</p> </li> </ul> <p>其实就是模拟的竖式除法。一个示例如下。</p> <p><img src="/assets/img/blog_post/co/cod-24.png" alt="cod-24" width="50%"/></p> </li> <li> <p>Division Ver 3</p> <p>和之前的 Multiplier V3 一致的思路：将 remainder 和 quotient 放在一个 reg 中存放。</p> <p><img src="/assets/img/blog_post/co/cod-25.png" alt="cod-25" width="50%"/></p> <p><img src="/assets/img/blog_post/co/cod-26.png" alt="cod-26" width="50%"/></p> <p>注意初始的时候就可以将 remainder 左移一位（对应 iter0，因为第一次必然失败）。最后 reg 中的 left half 即为 remainder，right half 即为 quotient。</p> </li> </ol> <h3 id="float">Float</h3> <ul> <li> <p>浮点数的存储与定义</p> <p>浮点数的存储分为三部分。</p> <ul> <li>float：符号位 $S$ (1bit)，指数位 $E$ (8bits)，系数位 $F$ (23bits)。</li> <li>double：符号位 $S$ (1bit)，指数位 $E$ (11bits)，系数位 $F$ (52bits)。</li> </ul> <p>其意义为二进制下的科学计数法表示：$(-1)^S \times 1.F \times 2^{E+bias}$。</p> <p>实际使用时指数位 $E$ 会有偏差 $bias$，这是为了处理 $E$ 可能为负的情况。对于 float，$E$ 存储值比实际值大 $bias=127$；对于 double，$E$ 存储值比实际值大 $bias=1023$。</p> <p>特别规定：</p> <ul> <li>当 $E=111…11, \ F=000…00$，表示此浮点数为无穷。</li> <li>当 $E=111…11, \ F \neq 000…00$，表示此浮点数为 NaN。</li> </ul> </li> <li> <p>浮点数加法</p> <p>算法流程与示例：</p> <ol> <li> <p>比较两数的指数位，确定大小关系并把指数位较小的通过 $F$ 右移（小数点则向左移动）使得两操作数的指数位 $E$ 一致。</p> </li> <li> <p>将 $F$ 相加。</p> </li> <li> <p>归一化（比如加法之后产生了进位，那么 $E$ 应当加一，$F$ 则右移）。</p> </li> <li> <p>Rounding（比如四舍五入）</p> </li> <li> <p>再次归一化（例如 9.99 round 后变为 10.00，此时需要再次归一化，当然这只是一个十进制的例子）</p> </li> </ol> <p><img src="/assets/img/blog_post/co/cod-27.png" alt="cod-27" width="50%"/></p> <p>逻辑结构图绘制：</p> <p><img src="/assets/img/blog_post/co/cod-28.png" alt="cod-28" width="50%"/></p> </li> <li> <p>浮点数乘法</p> <p>区别主要集中在：</p> <ol> <li>符号位单独处理</li> <li>指数位 $E$ 相加后要减去对应的 $bias$。</li> </ol> <p><img src="/assets/img/blog_post/co/cod-29.png" alt="cod-29" width="50%"/></p> </li> <li> <p>Accurate Arithmetic 浮点数精度问题</p> <p>一些术语：</p> <ul> <li> <p>保留位 (guard bit)：第一个被舍掉的位。</p> </li> <li> <p>近似位 (round bit)：guard bit 的后面一位，亦即第二个被舍掉的位。</p> </li> <li> <p>粘滞位 (sticky bit)：round bit 后面的所有位的 OR 构成 sticky bit。</p> </li> </ul> <p>Rounding 规则如下：</p> <p><img src="/assets/img/blog_post/co/cod-30.png" alt="cod-30" width="50%"/></p> </li> </ul>]]></content><author><name></name></author><category term="CourseNotes"/><category term="Hardware"/><summary type="html"><![CDATA[Contains content about CO introduction and arithmetic knowledge.]]></summary></entry><entry><title type="html">Computer Organization Note (Part 2 of 4)</title><link href="https://sqrtyz.github.io/blog/2024/CO-NOTE-2/" rel="alternate" type="text/html" title="Computer Organization Note (Part 2 of 4)"/><published>2024-01-01T12:00:00+00:00</published><updated>2024-01-01T12:00:00+00:00</updated><id>https://sqrtyz.github.io/blog/2024/CO-NOTE-2</id><content type="html" xml:base="https://sqrtyz.github.io/blog/2024/CO-NOTE-2/"><![CDATA[<h2 id="chapter-2-instructions-language-of-the-machine">Chapter 2. Instructions: Language of the Machine</h2> <h3 id="introduction">Introduction</h3> <ul> <li> <p>Process of Compiling</p> <p>编译过程：高级编程语言 $\to$ 汇编语言 $\to$ 机器语言。</p> <p>例如，<code class="language-plaintext highlighter-rouge">A + B</code> $\to$ <code class="language-plaintext highlighter-rouge">add A, B</code> $\to$ <code class="language-plaintext highlighter-rouge">1000110010100000</code>。</p> </li> <li> <p>Instruction</p> <p>指令是「机器的语言」。如果说 Instruction 是 Word，那么 Instruction set 则是 Vocabulary。</p> <p>本课程采取的指令集为 RISC-V。这是一种精简指令集。</p> <p>关于汇编语言和指令集的关系，摘取两条知乎回答：</p> <blockquote> <p>汇编语言是用人类看得懂的语言来描述指令集。否则指令集的机器码都是一堆二进制数字，人类读起来非常麻烦，但汇编是用类似人类语言的方式描述指令集，读起来方便多了。</p> </blockquote> <blockquote> <p>汇编指令是让人看得懂的，只是指令集的另外一种表示形式。</p> </blockquote> </li> <li> <p>RISC vs. CISC</p> <p><img src="/assets/img/blog_post/co/cod-31.png" alt="cod-31" width="50%"/></p> </li> </ul> <h3 id="basics-instructions-and-registers">Basics: Instructions and Registers</h3> <ul> <li> <p>Instruction Formats</p> <p><img src="/assets/img/blog_post/co/cod-32.png" alt="cod-32" width="50%"/></p> <p>前者是可以理解为操作类型，后者可以理解为操作参数。</p> </li> <li> <p>Register Operands</p> <p>对于 RISC-V 指令集，其使用的寄存器类型为 $32\times 64\text{-bit}$。可以想象成一个寄存器有 32 行，每一行有一个变量，其长度为 64 bits（等于 8 bytes，是一个 double / long long 的大小，也被称为 dword）。</p> <p>这些寄存器的「各行」各司其职。其职能如下表所示。</p> <p><img src="/assets/img/blog_post/co/cod-33.png" alt="cod-33" width="50%"/></p> <p>举个例子：<code class="language-plaintext highlighter-rouge">f = (g + h) - (i + j);</code>，我们假设目前 $f,g,h,i,j$ 的值分别位于地址 x19, x20, x21, x22, x23。</p> <p>那么我们应该这样描述 RISC-V 指令：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  add x5, x20, x21
  add x6, x22, x23
  sub x19, x5, x6
</code></pre></div> </div> </li> </ul> <h3 id="al-1-arithmetic-logical-and-memory">AL 1: Arithmetic, Logical and Memory</h3> <ul> <li> <p>Add and Subtraction</p> <table> <thead> <tr> <th>Category</th> <th>Instruction</th> <th>Example</th> <th>Meaning</th> <th>Comments</th> <th>Type</th> </tr> </thead> <tbody> <tr> <td>Arithmetic</td> <td>add</td> <td><code class="language-plaintext highlighter-rouge">add a,b,c</code></td> <td>$a \gets b+c$</td> <td>Always 3 operand</td> <td>R</td> </tr> <tr> <td>Arithmetic</td> <td>subtract</td> <td><code class="language-plaintext highlighter-rouge">sub a,b,c</code></td> <td>$a \gets b-c$</td> <td>Always 3 operand</td> <td>R</td> </tr> </tbody> </table> </li> <li> <p>Immediate Arithmetic</p> <table> <thead> <tr> <th>Category</th> <th>Instruction</th> <th>Example</th> <th>Meaning</th> <th>Comments</th> <th>Type</th> </tr> </thead> <tbody> <tr> <td>Arithmetic</td> <td>addi immediate</td> <td><code class="language-plaintext highlighter-rouge">addi a,b,c</code></td> <td>$a \gets b+c$</td> <td>$c$ is a constant</td> <td>I</td> </tr> </tbody> </table> </li> <li> <p>Logical Arithmetic</p> <p><img src="/assets/img/blog_post/co/cod-39.png" alt="cod-39" width="50%"/></p> <p><img src="/assets/img/blog_post/co/cod-40.png" alt="cod-40" width="50%"/></p> <p>（懒得敲表格了，直接截图）</p> </li> <li> <p>Memory Operations</p> <ul> <li> <p>Basics</p> <ol> <li>执行算术操作：先从 memory 中读到 reg，在 reg 中进行运算，最后输回到 reg。</li> <li>Memory 的地址是 <strong>按 byte 定义的</strong>。</li> <li>RISC-V 采取小端。</li> </ol> </li> <li> <p>Example</p> <p>考虑 C 代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">A</span><span class="p">[</span><span class="mi">12</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="mi">8</span><span class="p">];</span> <span class="c1">// here A is a double</span>
</code></pre></div> </div> <p>假设 h 在 reg 中的值位于 x21，A 在 memory 中的地址值保存在 reg 中的 x22。</p> <p>用 RISC-V 表示：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  ld x9, 64(x22)
  add x9, x21, x9
  sd x9, 96(x22)
</code></pre></div> </div> <ol> <li>第一行：由于 A 是 double 类型，所以 A[8] 相对于 A 的偏移为 64。<code class="language-plaintext highlighter-rouge">ld</code> 用于从 mem 读到 reg，使用 <code class="language-plaintext highlighter-rouge">ld x9, 64(x22)</code> 将 A 地址向后偏移 64 bytes 处的值读入到 reg 的 x9 中。</li> <li>第二行：执行加法。</li> <li>第三行：将 reg 的 x9 中的值输出到 mem 中。具体位置是 x22 所存地址向后偏移 96。</li> </ol> <table> <thead> <tr> <th>Category</th> <th>Instruction</th> <th>Example</th> <th>Meaning</th> <th>Comments</th> <th>Type</th> </tr> </thead> <tbody> <tr> <td>Data Transfer</td> <td>load dword</td> <td><code class="language-plaintext highlighter-rouge">ld x5, 40(x6)</code></td> <td>x5 = Mem[x6+40]</td> <td>dword from mem to reg</td> <td>I</td> </tr> <tr> <td>Data Transfer</td> <td>store dword</td> <td><code class="language-plaintext highlighter-rouge">sd x5, 40(x6)</code></td> <td>Mem[x6+40] = x5</td> <td>dword from reg to mem</td> <td>S</td> </tr> </tbody> </table> </li> </ul> </li> <li> <p>Sign Extension</p> <p>Example: 8-bit to 16-bit</p> <p>+2: 0000 0010 =&gt; 0000 0000 0000 0010</p> <p>-2: 1111 1110 =&gt; 1111 1111 1111 1110</p> <p>在 RISC-V 中，<code class="language-plaintext highlighter-rouge">lb</code> 操作用于执行「同符号位拓展」，<code class="language-plaintext highlighter-rouge">lbu</code> 操作用于执行「补 0 位拓展」。</p> </li> </ul> <h3 id="ml-1-representing-instructions-of-r--i--s">ML 1: Representing Instructions of R / I / S</h3> <ul> <li> <p>汇编码 $\to$ 机器码</p> <p>一个例子如下：</p> <p><img src="/assets/img/blog_post/co/cod-34.png" alt="cod-34" width="50%"/></p> <p>可以看到，汇编码向机器码的转换已经很好理解了。更具体一点，它的规则如下：</p> <p><img src="/assets/img/blog_post/co/cod-35.png" alt="cod-35" width="50%"/></p> <p>一条指令的长度恒为 32 位。注意构成 operator 的不止有 opcode，还有 funct7 和 funct3。例如，<code class="language-plaintext highlighter-rouge">add</code> 和 <code class="language-plaintext highlighter-rouge">sub</code> 的 opcode 实际上是相同的。</p> <p>实际上，这种机器码指令为 R 型指令，他只是众多机器码指令类型中的一种。</p> <p><img src="/assets/img/blog_post/co/cod-36.png" alt="cod-36" width="50%"/></p> <ul> <li> <p>R-Format Instructions</p> <p>主要包含 arithmetic。格式和意义如上所示。</p> </li> <li> <p>I-Format Instructions</p> <p>主要包含 immediate arithmetic 和 load instructions。</p> <p><img src="/assets/img/blog_post/co/cod-37.png" alt="cod-37" width="50%"/></p> </li> <li> <p>S-Format Instructions</p> <p>主要包含 store instructions。</p> <p><img src="/assets/img/blog_post/co/cod-38.png" alt="cod-38" width="50%"/></p> </li> </ul> </li> </ul> <h3 id="al-2-decision-instructions">AL 2: Decision Instructions</h3> <p>基本 RISC-V 语句：beq &amp; bne</p> <table> <thead> <tr> <th>Category</th> <th>Instruction</th> <th>Example</th> <th>Meaning</th> <th>Type</th> </tr> </thead> <tbody> <tr> <td>Decision</td> <td>equal</td> <td><code class="language-plaintext highlighter-rouge">beq rs1, rs2, L1</code></td> <td>if (<code class="language-plaintext highlighter-rouge">rs1 == rs2</code>) branch to instruction labeled L1</td> <td>SB</td> </tr> <tr> <td>Decision</td> <td>not equal</td> <td><code class="language-plaintext highlighter-rouge">bne rs1, rs2, L1</code></td> <td>if (<code class="language-plaintext highlighter-rouge">rs1 != rs2</code>) branch to instruction labeled L1</td> <td>SB</td> </tr> <tr> <td>Decision</td> <td>less than</td> <td><code class="language-plaintext highlighter-rouge">blt rs1, rs2, L1</code></td> <td>if (<code class="language-plaintext highlighter-rouge">rs1 &lt; rs2</code>) branch to instruction labeled L1</td> <td>SB</td> </tr> <tr> <td>Decision</td> <td>greater than</td> <td><code class="language-plaintext highlighter-rouge">bge rs1, rs2, L1</code></td> <td>if (<code class="language-plaintext highlighter-rouge">rs1 &gt;= rs2</code>) branch to instruction labeled L1</td> <td>SB</td> </tr> </tbody> </table> <p>Unsigned comparison: <code class="language-plaintext highlighter-rouge">bltu</code>, <code class="language-plaintext highlighter-rouge">bgeu</code>（在后面加 u 变成无符号）</p> <ul> <li> <p>单 if 情况</p> <p>考虑 C 代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">)</span> <span class="k">goto</span> <span class="n">L1</span><span class="p">;</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">g</span> <span class="o">+</span> <span class="n">h</span><span class="p">;</span>
  <span class="n">L1</span><span class="o">:</span> <span class="n">f</span> <span class="o">=</span> <span class="n">f</span> <span class="o">-</span> <span class="n">i</span><span class="p">;</span>
</code></pre></div> </div> <p>对应的 RISC-V 汇编代码：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  beq x21, x22, L1      # go to L1 if i equals j
  add x19, x20, x21     # f = g + h ( skipped if i equals j )
  L1: sub x19, x19, x22 # f = f - i ( always executed )
</code></pre></div> </div> </li> <li> <p>if-else 情况</p> <p>考虑 C 代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">)</span> <span class="n">f</span> <span class="o">=</span> <span class="n">g</span> <span class="o">+</span> <span class="n">h</span><span class="p">;</span>
  <span class="k">else</span> <span class="n">f</span> <span class="o">=</span> <span class="n">g</span> <span class="o">-</span> <span class="n">h</span><span class="p">;</span>
</code></pre></div> </div> <p>对应的 RISC-V 汇编代码（Assume that f~j are located at x19~x23）：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  bne x22, x23, Else  # go to Else if i != j
  add x19, x20, x21  # f = g + h ( Executed if i == j )
  beq x0, x0, EXIT  # always go to Exit
  Else: sub x19, x20, x21  # f = g - h ( Executed if i ≠ j ) 
  Exit:  # the first instruction of the next C 
</code></pre></div> </div> </li> <li> <p>LOOPs 情况</p> <p>考虑 C 代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nl">Loop:</span> <span class="n">g</span> <span class="o">=</span> <span class="n">g</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">];</span> <span class="c1">// A is an array of 100 words</span>
  <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">h</span> <span class="p">)</span> <span class="k">goto</span> <span class="n">Loop</span><span class="p">;</span>
</code></pre></div> </div> <p>对应的 RISC-V 汇编代码（Assume that f~j are located at x19~x23, base of A is stored in x25）：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Loop: slli x10, x22, 3 # temp reg x10 = 8 * i
  add x10, x10, x25      # x10 = address of A[i]
  ld x19, 0(x10)         # temp reg x19 = A[i]
  add x20, x20, x19      # g = g + A[i]
  add x22, x22, x23      # i = i + j
  bne x22, x21, Loop     # go to Loop if i != h
</code></pre></div> </div> <p>第一行 <code class="language-plaintext highlighter-rouge">x22</code> 乘以 $8$ 之后放入 <code class="language-plaintext highlighter-rouge">x10</code>，和第二行共同计算出了 $A_i$ 的内存地址，置于 x10。</p> <p>第三行将 $A_i$ 的值读入到 <code class="language-plaintext highlighter-rouge">x19</code>。注意此处 <code class="language-plaintext highlighter-rouge">0(x10)</code> 中 <code class="language-plaintext highlighter-rouge">0</code> 只能是常量，因而不能用之前的那种寻址方式。</p> </li> <li> <p>while 情况</p> <p>考虑 C 代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">while</span> <span class="p">(</span><span class="n">save</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>
      <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
</code></pre></div> </div> <p>对应的 RISC-V 汇编代码（Assume i~k are located at x22~x24, base of save is stored in x25）：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Loop: slli x10, x22, 3 # temp reg $t1 = 8 * i
  add x10, x10, x25      # x10 = address of save[i]
  ld x9, 0(x10)          # x9 gets save[i]
  bne x9, x24, Exit      # go to Exit if save[i] != k
  addi x22, x22, 1       # i += 1
  beq x0, x0, Loop       # go to Loop 
  Exit:
</code></pre></div> </div> </li> <li> <p>比较</p> <p>使用 <code class="language-plaintext highlighter-rouge">blt</code>, <code class="language-plaintext highlighter-rouge">bge</code> 表示变量比较形式的选择。例如 <code class="language-plaintext highlighter-rouge">blt rs1, rs2, L1</code> 表示如果 rs1 &lt; rs2 则跳到 L1 标签处的指令。</p> <p>注意 <code class="language-plaintext highlighter-rouge">bltu</code>, <code class="language-plaintext highlighter-rouge">bgeu</code> 表示无符号比较。使用这种比较方式可能会导致比较结果不同。</p> <p><img src="/assets/img/blog_post/co/cod-41.png" alt="cod-41" width="50%"/></p> </li> </ul> <h3 id="al-3-jump-register">AL 3: Jump Register</h3> <p>RISC-V 中的无条件跳转主要包含两种指令：<code class="language-plaintext highlighter-rouge">jal</code> 和 <code class="language-plaintext highlighter-rouge">jalr</code>。</p> <table> <thead> <tr> <th>Category</th> <th>Instruction</th> <th>Example</th> <th>Meaning</th> <th>Type</th> </tr> </thead> <tbody> <tr> <td>Unconditional branch</td> <td>jump and link</td> <td><code class="language-plaintext highlighter-rouge">jal x1, 100</code></td> <td>x1 = PC + 4; go to PC+100</td> <td>UJ</td> </tr> <tr> <td>Unconditional branch</td> <td>jump and link register</td> <td><code class="language-plaintext highlighter-rouge">jalr x1, 100(x5)</code></td> <td>x1 = PC + 4; go to x5+100</td> <td>I</td> </tr> </tbody> </table> <p>这之中 PC 的意思是当前指令的地址。实际上，所有指令都存储在内存之中（后面会再讲）。这里跳实际上也是一种「在内存里跳」。注意每个指令的长度为 32 bits。</p> <p><code class="language-plaintext highlighter-rouge">jal</code> 可以理解为相对位置跳转，<code class="language-plaintext highlighter-rouge">jalr</code> 可以理解为绝对位置跳转。</p> <ul> <li> <p>使用 Jump address table 来指导跳转</p> <p>考虑这样的 C 代码，其中 $f\sim k$ 存储在 x20 ~ x25 中。</p> <pre><code class="language-C">  switch ( k ) {
      case 0 : f = i + j ; break ; /* k = 0 */
      case 1 : f = g + h ; break ; /* k = 1 */
      case 2 : f = g - h ; break ; /* k = 2 */
      case 3 : f = i - j ; break ; /* k = 3 */
  }
</code></pre> <p>其 RISC-V 指令如下：</p> <p><img src="/assets/img/blog_post/co/cod-42.png" alt="cod-42" width="50%"/></p> <p>从内存中的 x6 开始一段，存储着我们用来辅助跳转的 Jump address table。第四行根据 $k$ 的值，将目标的精确 address 在内存中的存放位置赋给 x7。第五行执行后则 x7 获得了目标指令的 address（其实就是在内存 text 段的 address）。最后通过第六行跳转到对应指令。</p> </li> </ul> <h3 id="supporting-procedures">Supporting Procedures</h3> <p>本部分进一步讲解 jal, jalr, bne, beq 这类能搞跳转的指令。</p> <ul> <li> <p>指令的存储</p> <p>在将指令的存储前，首先讲内存的架构。</p> <p><img src="/assets/img/blog_post/co/cod-43.png" alt="cod-43" width="50%"/></p> <p>从下到上依次为：</p> <ol> <li>Reserved 此部分保留。</li> <li>Text 此部分 <strong>用于存储指令</strong>。之前看到指令的跳转也是以 byte 为单位的，这是因为它在内存之中，而内存的寻址亦为 byte 单位。</li> <li>Static Data 静态数据。这部分很好理解。</li> <li>Dynamic Data 动态数据。这部分很好理解。</li> <li>Stack 堆栈。这部分后面会讲，通常用于暂存一些 reg 中需要用到的量。</li> </ol> </li> <li> <p>常见的 Procedure Call 流程</p> <p>首先是 <strong>Caller</strong>。其指令一般为 <code class="language-plaintext highlighter-rouge">jal x1, ProcedureAddress</code>。注意此语句后， x1 中会 <strong>自动存放下一段指令的地址（即 PC + 4）</strong>。</p> <p>然后是 <strong>Callee</strong>。其指令一般为 <code class="language-plaintext highlighter-rouge">jalr x0, 0(x1)</code>。可以看到我们直接跳到 <code class="language-plaintext highlighter-rouge">(x1)</code>，因为在跳之前 <code class="language-plaintext highlighter-rouge">x1</code> 已被赋好了值；此外第一个 operand 为 <code class="language-plaintext highlighter-rouge">x0</code> 是因为我们不关心 callee 的地址，只用返回去即可（即没有必要存储 callee 的地址）。</p> </li> <li> <p>堆栈</p> <p>在指令跳转的途中，有可能我们后面希望跳回来，但同时也希望跳之前 Caller 使用的部分 reg 得以保留。通常这是很难做到的，所以我们使用堆栈来先将 Caller 使用的寄存器的值保存下来，Callee 使用寄存器后再复原，以便接下来 Caller 再使用。</p> <p>首先再次明确 RISC-V 寄存器的变量区域划分，同时我们也重新做一些记号：</p> <table> <thead> <tr> <th>Category</th> <th>Notation</th> <th>Register</th> </tr> </thead> <tbody> <tr> <td>Arguments</td> <td>a0 ~ a7</td> <td>x10 ~ x17</td> </tr> <tr> <td>Saved</td> <td>s0 ~ 11</td> <td>x8 ~ x9, x18 ~ x27</td> </tr> <tr> <td>Temporary</td> <td>t0 ~ t6</td> <td>x5 ~ x7, x28 ~ x31</td> </tr> </tbody> </table> <p>可以这样理解各类变量：比如在调用一个递归的 C 函数 <code class="language-plaintext highlighter-rouge">f(k)</code> 时，$k$ 和 $f(k)$ 的返回值都可以视作 Argument；而其中运算的中间值，递归完回来还要用的可视作 Saved；其中运算的中间值，递归完回来不用，仅仅作为中间运算结果的，可以视作 Temporary。</p> <p>之前讲到堆栈是地址最高的。同时，堆栈的 top 也是地址更低的。如下图所示。</p> <p><img src="/assets/img/blog_post/co/cod-44.png" alt="cod-44" width="50%"/></p> <p>考虑这样一个例子：C 代码实现递归阶乘</p> <pre><code class="language-C">  int fact ( int n ) {
      if ( n &lt; 1 ) return ( 1 ) ;
      else return ( n * fact ( n - 1 ) ) ;
  } 
</code></pre> <p>其 RISC-V 汇编代码如下：</p> <p><img src="/assets/img/blog_post/co/cod-45.png" alt="cod-45" width="50%"/></p> <p>Line 1-3 开了两个栈空间，并把 <code class="language-plaintext highlighter-rouge">ra</code> 和 <code class="language-plaintext highlighter-rouge">a0</code>（对应 x10，一般用于存储输入参数和输出结果）存入堆栈。</p> <p>Line 4-5 在比较 $n$ 和 $1$ 的关系。</p> <ul> <li> <p>如果 $ n \leq 1$，进入 <code class="language-plaintext highlighter-rouge">L1</code> (Line 9)。注意到 Line 9 首先将 <code class="language-plaintext highlighter-rouge">a0</code> 减了一以便开始下一层递归（这也是为什么开始要把 <code class="language-plaintext highlighter-rouge">a0</code> 存进堆栈）；Line 10 则跳转到 <code class="language-plaintext highlighter-rouge">fact</code> (Line 1)，此行指令也会把 <code class="language-plaintext highlighter-rouge">ra</code> 的值改变（这也是为什么开始要把 <code class="language-plaintext highlighter-rouge">ra</code> 存进堆栈）。</p> </li> <li> <p>执行完 $fact(n-1)$ 后，回到 Line 11。此时 <code class="language-plaintext highlighter-rouge">a0</code> 已然是递归后 $fact(n-1)$ 的结果，先把它转入 <code class="language-plaintext highlighter-rouge">t1</code> 临时变量中。随后读取之前存好的 <code class="language-plaintext highlighter-rouge">a0</code> 和 <code class="language-plaintext highlighter-rouge">ra</code>，读取之后 <code class="language-plaintext highlighter-rouge">a0</code> 就是当前进程的 argument（即 $n$），<code class="language-plaintext highlighter-rouge">ra</code> 就是要回去的 Caller 地址。</p> <p>Line 15 使得 <code class="language-plaintext highlighter-rouge">a0</code> 变身 result 为一会儿返回的 caller 服务。Line 16 跳回 Caller。</p> </li> </ul> <p><strong>SUMMARY</strong></p> <p>一般而言，caller 要对 temporary / argument 寄存器负责。即根据自己的情况决定这两类数据是否要存储到堆栈中。</p> <p>而 callee 则对 saved 寄存器和 ra 负责。按照约定，在使用 saved 寄存器前，callee 必须先将 saved 中的变量存入堆栈；此外，callee 在执行指令前必须先将 ra 存入寄存器来确保待会儿能重返 caller。</p> </li> </ul> <h3 id="other-width">Other Width</h3> <p>之前说的 load / store 都是以 dword 为单位的（指令为 <code class="language-plaintext highlighter-rouge">ld</code> 和 <code class="language-plaintext highlighter-rouge">sd</code>）。实际上也可以读写 byte / halfword / word。例如，要 load byte / halfword / word 的格式则为</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lb rd, offset(rs1)
lh rd, offset(rs1)
lw rd, offset(rs1)
</code></pre></div></div> <h3 id="ml-2-addressing-for-32-bit-immediate-and-addresses">ML 2: Addressing for 32-Bit Immediate and Addresses</h3> <p>这部分讲解 32 位立即数赋值 / 32 位寻址的机器码层面具体实现。</p> <ul> <li> <p>32-Bit Immediate Addressing (U-Type)</p> <p>指令 <code class="language-plaintext highlighter-rouge">lui</code>：将一个 register 的高 20 位设为常值。</p> <table> <thead> <tr> <th>Category</th> <th>Instruction</th> <th>Example</th> <th>Meaning</th> <th>Type</th> </tr> </thead> <tbody> <tr> <td>Data transfer</td> <td>Load upper immediate</td> <td><code class="language-plaintext highlighter-rouge">lui x5, 0x12345</code></td> <td>x5 = 0x12345000, Loads 20-bits constant shifted</td> <td>U</td> </tr> </tbody> </table> <p><img src="/assets/img/blog_post/co/cod-46.png" alt="cod-46" width="50%"/></p> <p>实际上的 RISC-V reg 是 64 位的。在这里我们对低 32 位赋予立即数。之所以要分两次赋予常值是因为一次的大小不够。</p> </li> <li> <p>Branch Addressing (SB-Type)</p> <p>上回说到 bne 的格式是 <code class="language-plaintext highlighter-rouge">bne rs1, rs2, L1</code> 其中 <code class="language-plaintext highlighter-rouge">L1</code> 是某个标签，表示了某处的指令。然而实际上机器肯定无法识别 <code class="language-plaintext highlighter-rouge">L1</code>，所以实际上这里 L1 翻译成机器码是一个 offset。</p> <p>举例：<code class="language-plaintext highlighter-rouge">bne x10, x11, 2000</code>（2000 = 0111 1101 0000）</p> <p><img src="/assets/img/blog_post/co/cod-47.png" alt="cod-47" width="50%"/></p> <p>上图的 Inst 那一行有些神金，首先一般不用 Inst 表示（就用 imm），然后应该最低位从 0 开始。</p> <p>注意，由于所有的 RISC-V 指令都是 32 位的（本课程不讨论 16 位），所以指令的地址（byte 单位）一定满足末两位为 0。所以 RISC-V 的设计者决定在实际机器编码时，省略 offset 的最后一位，只将 offset 中的非 LSB 部分写入机器码（这样可以使 offset 支持更远的距离）。</p> </li> <li> <p>Jump Addressing (UJ-Type)</p> <p>考虑 <code class="language-plaintext highlighter-rouge">jal</code> 指令，其指令格式为 UJ 型。</p> <p>举例：<code class="language-plaintext highlighter-rouge">jal x0 2000</code>，表示跳转到 $\text{offset} = 2000_{(10)}$ 的位置，没有向 <code class="language-plaintext highlighter-rouge">ra</code> 中存入内容。</p> <p><img src="/assets/img/blog_post/co/cod-48.png" alt="cod-48" width="50%"/></p> <p>其中 2000 (offset) 存储在 imm 部分；x0 存储在 rd 部分，表示的是某个寄存器地址。</p> <p>注意其中 <code class="language-plaintext highlighter-rouge">imm[20] (inst[31])</code> 表示的是 <strong>符号位</strong>。当其为 $1$ 实际上是往之前的指令跳。</p> <p>此外，和 Branch Addressing 一样，offset 的最后一位不再反映到机器码中，默认 offset 的最后一位一定为零。</p> </li> <li> <p>An Example: C $\to$ Assembly $\to$ Machine</p> <p><img src="/assets/img/blog_post/co/cod-49.png" alt="cod-49" width="50%"/></p> <p>解读 bne 那一行：rs1 表示的是 x9，rs2 表示的是 x24。对于 SB-Type 指令，funct7 和 rd 列共同组成了 immediate。可以看到本指令的立即数为 <code class="language-plaintext highlighter-rouge">000000000110(0)</code> （最后一个 0 在机器码中被省去），对应的就是 +12。而我们看到 bne 和 Exit 差 3 条指令，即为 12 Bytes。</p> </li> </ul> <h3 id="summary">SUMMARY</h3> <p><img src="/assets/img/blog_post/co/cod-36.png" alt="cod-36" width="50%"/></p> <p>个人感觉指令基本上是按「格式」分类，而不是「作用」分类。</p> <ul> <li> <p>R 型：<strong>主要用于「算术操作」</strong>。rd 表示被赋值寄存器，rs1 和 rs2 表示操作数。</p> </li> <li> <p>I 型：<strong>目前可用于「load」「立即数算术」「jalr」</strong>。load 和 jalr 的共同点是都有一个基地址 rs1，同时有一个偏移量 imm。随后它们的 rd 都会改变，load 会把内存中读到的值放进 rd，jalr 会把 PC+4 放进 rd。</p> </li> <li> <p>SB 型：<strong>目前可用于「选择型跳转」</strong>。rs1 和 rs2 执行某种比较运算，跳转的偏移量存储在 imm 中。</p> </li> <li> <p>UJ 型：<strong>目前可用于「jal」</strong>。jal 只有一个偏移量 offset，同时也会把 PC+4 放进 rd。</p> </li> <li> <p>U 型：<strong>目前可用于「立即数赋值」</strong>。把 imm 放进 rd（取低 32 位）的高 20 位。</p> </li> <li> <p>S 型：<strong>目前可用于「store」</strong>。store 会把 rs2 寄存器中的内容写入基地址 rs1，偏移量 imm 的位置。</p> </li> </ul> <p>可以看到，rs1 / rs2 / rd / imm 都是有其意义的。</p> <ul> <li> <p>imm 通常表示常量，所以也经常表示 offset。注意 imm 的「上下界」（比如 <code class="language-plaintext highlighter-rouge">imm[31:12]</code>）有其意义。大概是，如果 imm 用于表示某指令的 X 部分，则 <code class="language-plaintext highlighter-rouge">imm[a:b]</code> 表示 imm 部分表示的是 <code class="language-plaintext highlighter-rouge">X[a:b]</code>。</p> </li> <li> <p>rs1 通常表示基地址。也有的时候表示第一个操作数。</p> </li> <li> <p>rd 通常是一个会被写入新内容的寄存器地址。</p> </li> <li> <p>rs2 则通常表示第二个操作数。</p> </li> </ul> <h3 id="some-extensions-of-ch2">Some Extensions of CH2</h3> <ol> <li> <p>Synchronization in RISC-V (RISC-V 同步问题)</p> <p>考虑同时有两个处理器 P1 和 P2 在读写同一块内存。如果不进行同步 (Synchronization) 则有可能产生冲突。</p> <p>首先介绍两个新指令 <code class="language-plaintext highlighter-rouge">lr.d</code>，<code class="language-plaintext highlighter-rouge">sc.d</code>：</p> <table> <thead> <tr> <th>Category</th> <th>Instruction</th> <th>Example</th> <th>Meaning</th> </tr> </thead> <tbody> <tr> <td>Data transfer</td> <td>Load-Reserved Dword</td> <td><code class="language-plaintext highlighter-rouge">lr.d rd, (rs1)</code></td> <td>从内存中地址为 rs1 加载 8 个字节，写入 rd，并对内存 <strong>双字注册保留</strong></td> </tr> <tr> <td>Data transfer</td> <td>Store-Conditional Dword</td> <td><code class="language-plaintext highlighter-rouge">sc.d rd, rs2, (rs1)</code></td> <td>若内存地址 rs1 上存在加载保留，将 rs2 寄存器中的 8 字节数存入该地址，并向寄存器 rd 中存入 0；否则存入非 0 错误码</td> </tr> </tbody> </table> <p>简单来说，<code class="language-plaintext highlighter-rouge">lr.d</code> 会对地址为 <code class="language-plaintext highlighter-rouge">rs1</code> 的内存打上标记。若在下次 <code class="language-plaintext highlighter-rouge">rs1</code> 被 <code class="language-plaintext highlighter-rouge">sc.d</code> 之前 <code class="language-plaintext highlighter-rouge">rs1</code> 没被动过，则 <code class="language-plaintext highlighter-rouge">sc.d</code> 成功执行并返回 $0$；反之（被动过）则 <code class="language-plaintext highlighter-rouge">sc.d</code> 返回 $1$。</p> <p>接下来介绍两个例子，通过 <code class="language-plaintext highlighter-rouge">lr.d</code> 和 <code class="language-plaintext highlighter-rouge">sc.d</code> 来避免内存的读写冲突。</p> <ul> <li> <p>Example 1. Atomic Swap</p> <div class="language-as highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nx">again</span><span class="o">:</span> <span class="nx">lr</span><span class="p">.</span><span class="nx">d</span> <span class="nx">x10</span><span class="p">,</span> <span class="p">(</span><span class="nx">x20</span><span class="p">)</span>
  <span class="nx">sc</span><span class="p">.</span><span class="nx">d</span> <span class="nx">x11</span><span class="p">,</span> <span class="p">(</span><span class="nx">x20</span><span class="p">),</span> <span class="nx">x23</span>  <span class="c1">// X11 = status</span>
  <span class="nx">bne</span> <span class="nx">x11</span><span class="p">,</span> <span class="nx">x0</span><span class="p">,</span> <span class="nx">again</span>    <span class="c1">// branch if store failed</span>
  <span class="nx">addi</span> <span class="nx">x23</span><span class="p">,</span> <span class="nx">x10</span><span class="p">,</span> <span class="mi">0</span>      <span class="c1">// X23 = loaded value</span>
</code></pre></div> </div> <p>本段 RISC-V 指令实现了将寄存器 x23 和地址为 x20 的内存进行数值交换。注意如果 x11 非零说明 <code class="language-plaintext highlighter-rouge">sc.d</code> 不成功，即一二行指令之间可能发生了 x20 又被其他处理器覆写的情况。这种情况我们重新到 again 开始 swap，保证所有操作是 atomic 的。</p> </li> <li> <p>Example 2. Lock</p> <div class="language-as highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nx">addi</span> <span class="nx">x12</span><span class="p">,</span> <span class="nx">x0</span><span class="p">,</span> <span class="mi">1</span>         <span class="c1">// copy locked value</span>
  <span class="nl">again</span><span class="p">:</span> <span class="nx">lr</span><span class="p">.</span><span class="nx">d</span> <span class="nx">x10</span><span class="p">,</span> <span class="p">(</span><span class="nx">x20</span><span class="p">)</span>  <span class="c1">// read lock</span>
  <span class="nx">bne</span> <span class="nx">x10</span><span class="p">,</span> <span class="nx">x0</span><span class="p">,</span> <span class="nx">again</span>      <span class="c1">// check if it is 0 yet</span>
  <span class="nx">sc</span><span class="p">.</span><span class="nx">d</span> <span class="nx">x11</span><span class="p">,</span> <span class="p">(</span><span class="nx">x20</span><span class="p">),</span> <span class="nx">x12</span>    <span class="c1">// attempt to store</span>
  <span class="nx">bne</span> <span class="nx">x11</span><span class="p">,</span> <span class="nx">x0</span><span class="p">,</span> <span class="nx">again</span>      <span class="c1">// branch if fail</span>
</code></pre></div> </div> <p>To unlock:</p> <div class="language-as highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nx">sd</span> <span class="nx">x0</span><span class="p">,</span> <span class="mi">0</span><span class="p">(</span><span class="nx">x20</span><span class="p">)</span>           <span class="c1">// free lock</span>
</code></pre></div> </div> <p>x12 中始终为 1。若 x20 为 1（表示锁住状态）则会一直在二三行之间循环，也就是指令被锁在这里了。如果要解锁则将 x20 设为 0（表示解锁状态），此时能顺利通过第三行。</p> <p>通过第三行后，再次尝试对锁复位为 1。若复位成功，x11 为 0，通过第五行，离开本部分指令；如果复位失败，x11 不为 0，说明二四行之间可能发生了 x20 被其他处理器覆写的情况，说明锁还不能松（其它进程在进行），需要回到 again 处重新循环上锁。</p> </li> </ul> </li> <li> <p>Translating and starting a program (程序的编写和执行步骤)</p> <p><img src="/assets/img/blog_post/co/cod-50.png" alt="cod-50" width="50%"/></p> <ul> <li> <p>关于 obj 文件</p> <p>object 文件由六部分构成：</p> <ul> <li><strong>Header</strong>: described contents of object module</li> <li><strong>Text segment</strong>: translated instructions</li> <li><strong>Static data segment</strong>: data allocated for the life of the program</li> <li><strong>Relocation info</strong>: for contents that depend on absolute location of loaded program</li> <li><strong>Symbol table</strong>: global definitions and external refs</li> <li><strong>Debug info</strong>: for associating with source code</li> </ul> <p>一个例子如下，其中具有 A / B 两个程序的 obj 文件：</p> <p><img src="/assets/img/blog_post/co/cod-51.png" alt="cod-51" width="50%"/></p> <p>将其 Link 之后，生成 Executable 文件如下：</p> <p><img src="/assets/img/blog_post/co/cod-52.png" alt="cod-52" width="50%"/></p> </li> <li> <p>关于 Dynamic Linking &amp; Lazy Linkage</p> <p><img src="/assets/img/blog_post/co/cod-53.png" alt="cod-53" width="50%"/></p> <p>可以理解为，我在某个程序里调用了一个库函数 F，但实际上 F 的内容并没有被写入 Text 段，而是在其他位置。为了调用时跳转到该位置，我需要先在 Memory Data（记为 MD）中找到 DLL（动态链接库）的位置，然后跳过去；而后 DLL 会告诉我（为我分配）F 的准确位置，然后我再跳一次。是为 Dynamic Linking。</p> <p>第二次调用库函数 F 时，MD 就已经存放了我要的 F 的位置了，直接就可以跳过去。是为 Lazy Linkage。</p> </li> </ul> </li> <li> <p>A C Sort Example To Put it All Together</p> <p>见讲义。一个主要思想是，把 C 转化成汇编语言的范式：</p> <p>Step 1. Allocate registers to program variables</p> <p>Step 2. Produce code for the body of the procedures</p> <p>Step 3. Preserve registers across the procedures invocation</p> </li> </ol>]]></content><author><name></name></author><category term="CourseNotes"/><category term="Hardware"/><summary type="html"><![CDATA[Contains content about ISA.]]></summary></entry><entry><title type="html">Computer Organization Note (Part 3 of 4)</title><link href="https://sqrtyz.github.io/blog/2024/CO-NOTE-3/" rel="alternate" type="text/html" title="Computer Organization Note (Part 3 of 4)"/><published>2024-01-01T12:00:00+00:00</published><updated>2024-01-01T12:00:00+00:00</updated><id>https://sqrtyz.github.io/blog/2024/CO-NOTE-3</id><content type="html" xml:base="https://sqrtyz.github.io/blog/2024/CO-NOTE-3/"><![CDATA[<h2 id="chapter-4-1-processor-single-cycle-ver">Chapter 4-1 Processor: Single Cycle Ver</h2> <h3 id="introduction">Introduction</h3> <p>基本的思路是，在之前我们学习了 C -&gt; Assembly Language -&gt; Machine Code 的过程。而 CPU 的工作就是执行机器码。例如，对于指令 <code class="language-plaintext highlighter-rouge">add x10, x11, x12</code>，我们要用 CPU 完成以下工作：</p> <ul> <li> <p>读取 <code class="language-plaintext highlighter-rouge">x11</code> 和 <code class="language-plaintext highlighter-rouge">x12</code></p> </li> <li> <p>计算两者的和</p> </li> <li> <p>把和写到 <code class="language-plaintext highlighter-rouge">x10</code> 中</p> </li> </ul> <p>在本门课程中，我们主要关心以下指令：</p> <table> <thead> <tr> <th>Inst Type</th> <th>Inst</th> </tr> </thead> <tbody> <tr> <td>R-Type</td> <td>Arithmetic (<code class="language-plaintext highlighter-rouge">add</code>, <code class="language-plaintext highlighter-rouge">sub</code>, <code class="language-plaintext highlighter-rouge">and</code>, …)</td> </tr> <tr> <td>I-Type</td> <td>Load Register (<code class="language-plaintext highlighter-rouge">ld</code>)</td> </tr> <tr> <td>S-Type</td> <td>Store Register (<code class="language-plaintext highlighter-rouge">sd</code>)</td> </tr> <tr> <td>SB-Type</td> <td>Branch Jump (<code class="language-plaintext highlighter-rouge">beq</code>)</td> </tr> <tr> <td>UJ-Type</td> <td>Unconditional Jump (<code class="language-plaintext highlighter-rouge">jal</code>)</td> </tr> </tbody> </table> <h3 id="the-entire-processor">The Entire Processor</h3> <p><img src="/assets/img/blog_post/co/cod-54.png" alt="cod-54" width="50%"/></p> <p>其实整个一节的关键信息就这一幅图。其中的一些关键点：</p> <ul> <li> <p>PC 表示当前的指令位置。</p> </li> <li> <p>Instruction Memory 存放的是系列指令，可以理解为内存中的 Text 段。</p> </li> <li> <p>Registers 寄存器。RISC-V 具有 32 个各 64 位的寄存器。</p> </li> <li> <p>Data Memory 存放的是各种数据，可理解为内存中的 Data 段。</p> </li> </ul> <p>黑色的部分对应 CPU 的 Data Path，蓝色的部分对应 CPU 的 Control Unit。可以看到，Control 部分由 Opcode 全权完成。</p> <p>接下来根据指令类型的不同，详细分析数据的走向。注意下面的图片仅作示意，不一定严谨。有的图片还有订正。</p> <h3 id="processor-datapath-details">Processor Datapath Details</h3> <h4 id="1-r-type">1. R-Type</h4> <p><img src="/assets/img/blog_post/co/cod-55.png" alt="cod-55" width="50%"/></p> <h4 id="2-i-type-only-ld">2. I-Type (ONLY ld)</h4> <p><img src="/assets/img/blog_post/co/cod-58.png" alt="cod-58" width="50%"/></p> <p><strong>[ATTENTION]</strong> 图片有点问题，指令中的 <code class="language-plaintext highlighter-rouge">rs1</code> 连到寄存器的 <code class="language-plaintext highlighter-rouge">rs2</code> 上了，应当连到 <code class="language-plaintext highlighter-rouge">rs1</code> 上。</p> <ul> <li>其中 <code class="language-plaintext highlighter-rouge">20{inst[31]}</code> 是在做符号位拓展，因为本来也支持立即数为负的情况。</li> </ul> <h4 id="3-s-type-only-sd">3. S-Type (ONLY sd)</h4> <p><img src="/assets/img/blog_post/co/cod-57.png" alt="cod-57" width="50%"/></p> <h4 id="4-sb-type-only-beq">4. SB-Type (ONLY beq)</h4> <p><img src="/assets/img/blog_post/co/cod-56.png" alt="cod-56" width="50%"/></p> <ul> <li>这里 ALU 执行的是 sub 运算，然后根据 <code class="language-plaintext highlighter-rouge">zero</code> 判断是否相等。如果 <code class="language-plaintext highlighter-rouge">zero</code> 为 1（beq 条件满足）且 <code class="language-plaintext highlighter-rouge">branch</code> 为 1（本条指令为 beq），那么就开跳。</li> </ul> <h4 id="5-uj-type-only-jal">5. UJ-Type (ONLY jal)</h4> <p><img src="/assets/img/blog_post/co/cod-59.png" alt="cod-59" width="50%"/></p> <ul> <li>注意是 PC+4 进入到 <code class="language-plaintext highlighter-rouge">Write Data</code> 中。</li> </ul> <h3 id="controller">Controller</h3> <p>回顾一开始整个单周期 CPU 的图片，我们再贴一次：</p> <p><img src="/assets/img/blog_post/co/cod-54.png" alt="cod-54" width="50%"/></p> <p>根据 Opcode，我们需要通过 Controller 给出以下 8 个具体信号：</p> <ul> <li>R/W - RegWrite (0/1): 控制是否向寄存器里面写入。</li> <li>R/W - MemRead (0/1): 控制是否从内存读取。</li> <li>R/W - MemWrite (0/1): 控制是否向内存中写入数据。</li> <li>MUX - ALUSrc (0/1): 控制 ALU 下侧的数据来源，0 表示 rs2，1 表示 ImmGen。</li> <li>MUX - Branch (0/1): 表示当前指令是否为 branch jumping，用于控制下一个 PC。0 表示不为 branch，1 表示为 branch。结合 Zero 进行食用。</li> <li>MUX - Jump (0/1): 控制 PC 是否进行无条件跳转。例如当前指令为 <code class="language-plaintext highlighter-rouge">jal</code> 时该值为 1。</li> <li>MUX - MemtoReg (2 bits): 控制返回到 write address 中的数据来源。分别表示 PC+4，内存读出数据，ALU 计算结果。</li> <li>ALU op (2 bits): 用于指导 ALU 进行的运算类型。后续会过一次 ALU Control。</li> </ul> <p><strong>接下来专门讲一下 ALU 的具体控制</strong>。可以看到，ALU 的控制可以视为「两级」：</p> <ul> <li> <p>第一级：根据 ALU op 将不同类别的指令进行基础区分。</p> </li> <li> <p>第二级：相同 ALU op 的基础上，再根据 funct3 和 funct7 对不同运算的指令进行区分（这部分 funct 从上图的 <code class="language-plaintext highlighter-rouge">inst[30,14:12]</code> 线钻进去）。</p> </li> </ul> <p><img src="/assets/img/blog_post/co/cod-60.png" alt="cod-60" width="50%"/></p> <p>或许可以回顾一下 ALU：</p> <p><img src="/assets/img/blog_post/co/cod-9.png" alt="cod-9" width="50%"/></p> <h2 id="chapter-4-2-processor-pipeline-ver">Chapter 4-2 Processor: Pipeline Ver</h2> <h3 id="intro">Intro</h3> <ul> <li> <p>不同指令耗时不一</p> <p>例如在下图中，假设各部分的操作时长为：Memory Access, 200ps; ALU, 200ps; RegFile Access, 100ps。</p> <p>那么执行一次 <code class="language-plaintext highlighter-rouge">ld</code> 指令耗时为 800ps。执行一次 <code class="language-plaintext highlighter-rouge">sd</code> 指令耗时为 700ps。</p> <p><img src="/assets/img/blog_post/co/cod-61.png" alt="cod-61" width="80%"/></p> </li> <li> <p>Pipelining Analogy</p> <p>一种优化思路是从瓶颈（例如 <code class="language-plaintext highlighter-rouge">ld</code>）下手。然而我们还有另外一种优化思路——将【单周期 CPU】改为【流水线 CPU】。所谓流水线，可以参照这幅图：</p> <p><img src="/assets/img/blog_post/co/cod-62.png" alt="cod-62" width="70%"/></p> <p>对应到 CPU 中，我们可以尝试把其分为若干个区域（或步骤），让每个区域同时工作，实现整体的流水线工作。</p> </li> </ul> <h3 id="risc-v-pipeline-intro">RISC-V Pipeline Intro</h3> <p>RISC-V CPU 可以划分为以下五个阶段：</p> <ol> <li><strong>IF</strong>: Instruction fetch from memory</li> <li><strong>ID</strong>: Instruction decode &amp; read from register</li> <li><strong>EX</strong>: Execute operation or calculate address (ALU Part)</li> <li><strong>MEM</strong>: Access memory operand</li> <li><strong>WB</strong>: Write result back to register</li> </ol> <p>然后，一种简单的思路就是，我让五个阶段「流水线式」地工作，下图地两张图生动地说明了这一原理：</p> <p><img src="/assets/img/blog_post/co/cod-63.png" alt="cod-63" width="90%"/></p> <p><img src="/assets/img/blog_post/co/cod-64.png" alt="cod-64" width="90%"/></p> <p>理想情况下，这一转变将让 CPU 提速 5 倍（因为有 5 个阶段，当然实际不会到达这个数值，看上图的下半部分可以理解；而且后面还有各种 hazards）。</p> <h3 id="hazards">Hazards</h3> <p>中文意为「冒险」，表示流水线 CPU 实现中可能遇到的各种容易出问题的情况。</p> <h4 id="1-structure-hazard">1. Structure Hazard</h4> <p>可以想象，如果 data memory 和 instruction memory 是在同一部分的话，在 pipeline 的情形下，有的周期会调用同一块内存，这将产生冲突。</p> <p>好在 RISC-V 的设计将 data memory 和 instruction memory 分隔开，所以我们几乎不用考虑 Structure Hazard。</p> <h4 id="2-data-hazard">2. Data Hazard</h4> <ul> <li> <p>Problem: Data Hazard</p> <p>有的时候执行某一个指令，要求前一个指令完成数据写入。考虑这样的两个相邻指令：</p> <pre><code class="language-ass">  add x19, x0, x1
  sub x2, x19, x3
</code></pre> <p><img src="/assets/img/blog_post/co/cod-65.png" alt="cod-65" width="90%"/></p> <p>add 指令的 WB 必须要在 sub 指令的 ID 之前执行（原因显然），所以两个指令之间无法再「紧密地排列在流水线上」，中间需要隔两个 bubble。</p> <p>【OBSERVATION】观察上上张图，WB 的写 reg 是在上半 cycle，ID 的读 reg 是在下半 cycle。这种设计的缘由其实在这里有所体现。</p> </li> <li> <p>Solution: Forwarding</p> <p>解决这种情况的一种方案是 Forwarding。大概思路是有的时候我们不必等待一个数据被写入 reg，然后才再次使用；而是可以直接用某种 extra connection 来直接高效地使用。下图演示了 Forwarding 的解决方案。</p> <p><img src="/assets/img/blog_post/co/cod-66.png" alt="cod-66" width="90%"/></p> <p>然而，并非所有 Data Hazard 都可以用 Forwarding 解决。考虑这样的情形：</p> <p><img src="/assets/img/blog_post/co/cod-67.png" alt="cod-67" width="90%"/></p> <p>显然 sub 已经没办法再提前一个 cycle 了，不然 sub 的 EX 和 ld 的 MEM 将处在同一 cycle，而 sub 的 EX 需要 ld 的 MEM 提供前提数据。</p> <p>不过，也可以通过修改汇编代码来规避这一问题——</p> <p><img src="/assets/img/blog_post/co/cod-68.png" alt="cod-68" width="90%"/></p> </li> </ul> <h4 id="3-control-hazard">3. Control Hazard</h4> <ul> <li> <p>Problem: Stall on Branch</p> <p><img src="/assets/img/blog_post/co/cod-69.png" alt="cod-69" width="80%"/></p> <p>类似于这种 Branch Jumping 带来的停顿。上图有点问题，按理来说应当是两行 bubble。</p> </li> <li> <p>Solution: Branch Prediction</p> <p>字面意思，提前预测 branch 的结果。一般可以分为静态预测 (Static branch prediction) 和动态预测 (Dynamic branch prediction)。</p> <p>静态预测一般是在软件层面上，根据普遍的 branch 选择结果进行预测。</p> <p>动态预测一般是在硬件层面上，比如可以基于上一次 branch 的选择结果进行预测（考虑循环的情形，这种预测应当是成功率较高的）。</p> </li> </ul> <h3 id="risc-v-pipelined-datapath">RISC-V Pipelined Datapath</h3> <p>在解决这一系列 hazards 之前，我们需要对 CPU 的结构进行修改。总的图形如下：</p> <p><img src="/assets/img/blog_post/co/cod-70.png" alt="cod-70" width="100%"/></p> <ul> <li> <p>四个中间寄存器：<code class="language-plaintext highlighter-rouge">IF/ID</code>，<code class="language-plaintext highlighter-rouge">ID/EX</code>，<code class="language-plaintext highlighter-rouge">EX/MEM</code> 以及 <code class="language-plaintext highlighter-rouge">MEM/WB</code>。</p> <p>字面意思表明了其所处位置。引入寄存器的目的是显而易见的，是为了使得在流水线上，每个周期的指令依然能正确读取数据。比如观察 Reg 的 Write Data 输入，肯定得引入 <code class="language-plaintext highlighter-rouge">MEM/WB</code> 的值，而不是当前 Instruction Memory 的值。它们之间差了有 3 个 CC。</p> <p>注意这个改变只是最基本的，保证 pipeline 能正常运作的。它还没有解决 hazards 的问题。</p> </li> <li> <p>Control 信号：<code class="language-plaintext highlighter-rouge">EX</code>，<code class="language-plaintext highlighter-rouge">MEM(M)</code> 以及 <code class="language-plaintext highlighter-rouge">WB</code>。</p> <p>回顾单周期 CPU，除去 <code class="language-plaintext highlighter-rouge">jal</code> 使用的 jump 信号，Controller 一共给出 7 个信号。根据其作用阶段的不同，将其分为</p> <ol> <li> <p>EX (作用于 EX 阶段)：包含 <code class="language-plaintext highlighter-rouge">ALUop</code>，<code class="language-plaintext highlighter-rouge">ALUsrc</code>。</p> </li> <li> <p>MEM (作用于 MEM 阶段)：包含 <code class="language-plaintext highlighter-rouge">Branch</code>，<code class="language-plaintext highlighter-rouge">MemRead</code>，<code class="language-plaintext highlighter-rouge">MemWrite</code>。</p> </li> <li> <p>WB (作用于 WB 阶段)：包含 <code class="language-plaintext highlighter-rouge">MemToReg</code>，<code class="language-plaintext highlighter-rouge">RegWrite</code>。</p> </li> </ol> <p>可以看到，在流水线上 Controller 对应的寄存器的大小是越来越小的，这一点也很好理解，毕竟到后面的 stage 某些 control signal 就不再起作用了。</p> </li> </ul> <h3 id="data-hazard-solution">Data Hazard Solution</h3> <h4 id="1-r-r-case">1. R-R Case</h4> <p>情景：考虑以下的 RISC-V 指令：</p> <pre><code class="language-asm">sub x2, x1, x3
and x12, x2, x5
or x13, x6, x2
add x14, x2, x2
sd x15, 100(x2)
</code></pre> <p><img src="/assets/img/blog_post/co/cod-71.png" alt="cod-71" width="100%"/></p> <p>从上图可以看出，Data Hazard 发生当且仅当</p> <ul> <li> <p>前序指令的 <code class="language-plaintext highlighter-rouge">rd</code> 和后序指令的 <code class="language-plaintext highlighter-rouge">rs1/rs2</code> 重合，即</p> <p>1a. <code class="language-plaintext highlighter-rouge">EX/MEM.RegisterRd</code> = <code class="language-plaintext highlighter-rouge">ID/EX.RegisterRs1</code></p> <p>1b. <code class="language-plaintext highlighter-rouge">EX/MEM.RegisterRd</code> = <code class="language-plaintext highlighter-rouge">ID/EX.RegisterRs2</code></p> <p>2a. <code class="language-plaintext highlighter-rouge">MEM/WB.RegisterRd</code> = <code class="language-plaintext highlighter-rouge">ID/EX.RegisterRs1</code></p> <p>2b. <code class="language-plaintext highlighter-rouge">MEM/WB.RegisterRd</code> = <code class="language-plaintext highlighter-rouge">ID/EX.RegisterRs2</code></p> <p>四条中有一条满足即可。</p> </li> <li> <p>执行写入操作</p> <p><code class="language-plaintext highlighter-rouge">EX/MEM.Controller.RegWrite</code> $= 1$</p> <p><code class="language-plaintext highlighter-rouge">MEM/WB.Controller.RegWrite</code> $= 1$</p> <p>要求哪条满足主要是看上面选的是 1 还是 2。</p> </li> <li> <p>不是虚空写入</p> <p><code class="language-plaintext highlighter-rouge">EX/MEM.RegisterRd</code> $\neq 0$</p> <p><code class="language-plaintext highlighter-rouge">MEM/WB.RegisterRd</code> $\neq 0$</p> <p>要求哪条满足主要是看上面选的是 1 还是 2。</p> </li> </ul> <p>所以，我们可以加入这样的逻辑来完成 Forwarding：</p> <p><img src="/assets/img/blog_post/co/cod-72.png" alt="cod-72" width="100%"/></p> <h4 id="2-load-r-case">2. Load-R Case</h4> <p>情景：考虑以下的 RISC-V 指令：</p> <pre><code class="language-asm">ld x2, 20(x1)
and x4, x2, x5
or x8, x2, x6
add x9, x4, x2
</code></pre> <p><img src="/assets/img/blog_post/co/cod-73.png" alt="cod-73" width="100%"/></p> <p>可以发现，第二行的指令无论如何都没有机会执行了，所以 <code class="language-plaintext highlighter-rouge">add x4, x2, x5</code> 必然会推后一个 CC。对于这一情况的判断，我们可以在上图橙色处完成。判断条件为</p> <ul> <li> <p>前序指令的 <code class="language-plaintext highlighter-rouge">rd</code> 和后序指令的 <code class="language-plaintext highlighter-rouge">rs1/rs2</code> 重合，即</p> <p>a. <code class="language-plaintext highlighter-rouge">ID/EX.RegisterRd = IF/ID.RegisterRs1</code></p> <p>b. <code class="language-plaintext highlighter-rouge">ID/EX.RegisterRd = IF/ID.RegisterRs2</code></p> <p>两条中有一条满足即可。注意上面条件的两侧不要搞反。</p> </li> <li> <p>执行 Load 操作</p> <p><code class="language-plaintext highlighter-rouge">ID/EX.Controller.MemRead</code> $= 1$</p> </li> </ul> <p>如果条件满足，我们首先要进行 Stall（熄火）。操作为</p> <ol> <li> <p>将当前指令（也就是下一个 CC 的 ID/EX）寄存器全部归零。</p> </li> <li> <p>再次读取 PC，即不调到 PC+4。</p> </li> </ol> <p>Stall 后，我们再执行 Forwarding 来保证指令的正常运行。这一部分的 Forwarding 操作和 R-R Case 几乎一致，唯一的区别是 Forwarding 的执行是在判断生效的两个 CC 后。</p> <p>下图展示了考虑 Load-R Case 的 Pipeline。可以看到主要区别是加入了 Stall 的考量。</p> <p><img src="/assets/img/blog_post/co/cod-74.png" alt="cod-74" width="100%"/></p> <h3 id="branch-hazard-solution">Branch Hazard Solution</h3> <h4 id="1-static-prediction">1. Static Prediction</h4> <p>考虑以下指令：</p> <pre><code class="language-asm">36: sub x10, x4, x8
40: beq x1, x3, 32 // PC-relative branch to 40+32=72
44: and x12, x2, x5
48: orr x13, x2, x6
52: add x14, x4, x2
56: sub x15, x6, x7
...
72: ld x4, 50(x7)
</code></pre> <p>我们假设采取静态预测（预测为 Not Taken），那么有</p> <p><img src="/assets/img/blog_post/co/cod-75.png" alt="cod-75" width="90%"/></p> <p>判断预测是否正确是看 <code class="language-plaintext highlighter-rouge">x1</code> 和 <code class="language-plaintext highlighter-rouge">x3</code> 是否相等。如果预测正确（的确为 Not Taken），则无事发生，所有指令照常进入流水线；如果预测错误（实际为 Taken），则需要</p> <ul> <li> <p>立刻对 IF/ID 寄存器进行 Flush，使得其下一个周期为 Bubble</p> </li> <li> <p>向 PC 中输入 PC+Offset，使 IF 获取跳转后的指令</p> </li> </ul> <p><img src="/assets/img/blog_post/co/cod-76.png" alt="cod-76" width="90%"/></p> <h4 id="2-dynamic-prediction">2. Dynamic Prediction</h4> <p>基本思路是，根据之前 branch 的选择结果决定之后的选择结果。这样做的依据是，假设我们处于一个循环体之中，大多数时候我们需要 take branch，只有循环开始 / 结束的时候才是 not take branch。</p> <ul> <li> <p>1-bit predictor</p> <p>拿一个一位的寄存器存储上一次的 branch 结果。下一次 predict 根据这个 1-bit predictor 做出预测。</p> </li> <li> <p>2-bit predictor</p> <p>只会在连续两次的错误预测之后才会更改预测。从直观上看这个 predictor 更为「固执」。</p> <p><img src="/assets/img/blog_post/co/cod-77.png" alt="cod-77" width="60%"/></p> </li> </ul> <h4 id="3-calculating-the-branch-target">3. Calculating the Branch Target</h4> <p>很明显，计算要跳到哪里 (Branch Target) 需要使用 ALU 进行计算，这会导致一定的延迟。</p> <p><strong>Branch Target Buffer</strong> 可以直接缓存下跳转的地址，下次就可以直接跳转并获取对应的指令。</p> <h3 id="exceptions-and-interrupts">Exceptions and Interrupts</h3> <ul> <li> <p>可能导致异常与中断的情况</p> <p>异常：例如未定义的 opcode, syscall 等。</p> <p>中断：例如外界 I/O 进行了操作导致指令中断。</p> </li> <li> <p>基本处理方法</p> <ol> <li>SEPC: 可以理解为存储出问题的 PC 的一个寄存器。</li> <li>SCAUSE: 可以理解为存储问题信息的一个寄存器。例如，SCAUSE 可以存储 opcode / hardware malfunction 等。</li> <li>handler: 可以理解为用于处理问题的专门指令。假设其地址位于 <code class="language-plaintext highlighter-rouge">0000 0000 1C09 0000</code>。</li> </ol> <p>出问题时，先将 PC 存储到 SEPC 中，然后跳到专门的 handler。</p> <p>handler 决定该采取何种措施。如果程序可重启，则采取适当措施后通过 SEPC 跳回去；反之则需要终止程序，根据 SEPC 和 SCAUSE 等信息报错。</p> </li> <li> <p>Pipeline with Exceptions</p> <p>可以看到，相比于处理 hazards 的 pipeline，这玩意儿主要是多了几个后面的指令寄存器的 flush。</p> <p><img src="/assets/img/blog_post/co/cod-78.png" alt="cod-78" width="90%"/></p> <p>具体地，例如 <code class="language-plaintext highlighter-rouge">add x1, x2, x1</code> 在 ALU 阶段发生异常，我们会执行以下步骤：</p> <ol> <li>保护 <code class="language-plaintext highlighter-rouge">x1</code> 不被异常地写入。</li> <li>完成 <code class="language-plaintext highlighter-rouge">add x1, x2, x1</code> 之前的指令。</li> <li>flush 掉 <code class="language-plaintext highlighter-rouge">add</code> 及之前的所有正在处理的指令（寄存器置零）。</li> <li>设置好 SEPC 和 SCAUSE。</li> <li>跳转到 handler。</li> </ol> </li> <li> <p>Multiple Exceptions</p> <p>多重异常的情况，一般是处理最先出现的异常。</p> </li> </ul> <h3 id="instruction-level-parallelism-ilp">Instruction-Level Parallelism (ILP)</h3> <p>之前提到的 CPU 加速的方法是流水线，此外还有一种可能是：指令并行 (ILP)。</p> <p>可以预见，这是一种非常冒险的举动，但它的确可以为 CPU 再提一下速度。</p> <h4 id="1-introduction-and-terms">1. Introduction and Terms</h4> <ul> <li> <p>Multiple Issue (多发)</p> <p>可分为 static multiple issue 和 dynamic multiple issue。</p> <p>Static Multiple Issue: 编译器来决定把哪些指令「捆在一起」，以规避可能发生的 hazards。</p> <p>Dynamic Multiple Issue: CPU 来检测指令流并决定把那些指令「捆在一起」，编译器只起到辅助作用。显然这个难度更大。</p> </li> <li> <p>Speculation (前瞻执行)</p> <p>某些指令可以更早地执行（例如，提前预测并执行 branch outcome 处的指令）。当然，如果 speculation 是错误的，则需要 rollback。</p> <p>前瞻执行可以由编译器完成，亦可以由硬件完成。</p> <p>可以结合接下来的 RISC-V 静态双指令并行的例子理解 speculation。</p> </li> </ul> <h4 id="2-static-multiple-issue">2. Static Multiple Issue</h4> <p>显然，静态多发要求各个 issue slot 之内的指令互不依赖。当然，issue slot 之间的指令是可能产生依赖的。必要时，编译器可能向某个 issue slot 中加入 bubble。</p> <ul> <li> <p>RISC-V 静态双指令并行</p> <p>基本思路：一个 issue slot 装两个指令，其中一个只能为 ALU/branch，另外一个只能是 load/store。例如：</p> <p><img src="/assets/img/blog_post/co/cod-79.png" alt="cod-79" width="70%"/></p> <p>考虑双指令并行的流水线 CPU 如下图所示：</p> <p><img src="/assets/img/blog_post/co/cod-80.png" alt="cod-80" width="90%"/></p> <p>例如，我们可以看到 ALU 多了一个，并且多出来的那个不再接 MUX。这是因为 ld/sd 用的 ALU，其 ALUSource 已经固定。</p> <hr/> <p>当然，「打包」不能乱打。例如以下两条指令显然是不能位于同一个 issue slot 的：</p> <pre><code class="language-asm">  add x10, x0, x1
  ld x2, 0(x10)
</code></pre> <p>一个打包的正确示例如下：</p> <p><img src="/assets/img/blog_post/co/cod-81.png" alt="cod-81" width="70%"/></p> <p>注意：</p> <ol> <li><code class="language-plaintext highlighter-rouge">ld x31, 0(x20)</code> 和 <code class="language-plaintext highlighter-rouge">add x31, x31, x21</code> 中间还隔了一个 CC，这是因为 load-use hazard 中间必须要空一个 CC。</li> <li><code class="language-plaintext highlighter-rouge">sd x31, 0(x20)</code> 变为 <code class="language-plaintext highlighter-rouge">sd x31, 8(x20)</code>，这是因为我们把 <code class="language-plaintext highlighter-rouge">addi</code> 移到了 <code class="language-plaintext highlighter-rouge">sd</code> 之前。所以后做 <code class="language-plaintext highlighter-rouge">sd</code> 的话就需要做一些调整。</li> <li><code class="language-plaintext highlighter-rouge">add x31, x31, x21</code> 和 <code class="language-plaintext highlighter-rouge">sd x31, 8(x20)</code> 之间的 data hazard 处理方法和之前讲的 R-R 基本一致，也是可以用 forwarding 无缝链接的。</li> </ol> </li> <li> <p>循环展开</p> <p>编译器层面 / 高级语言层面对循环进行展开，有利于指令并行加速。</p> <p>这个例子执行了对相邻内存中的数据增加一个固定值 <code class="language-plaintext highlighter-rouge">x21</code>。使用循环展开来使得 ALU/branch 和 load/store 能更好地耦合。</p> <p><img src="/assets/img/blog_post/co/cod-82.png" alt="cod-82" width="70%"/></p> </li> </ul> <h4 id="3-dynamic-multiple-issue">3. Dynamic Multiple Issue</h4> <ul> <li> <p>动态调整指令的顺序</p> <p>为了实现动态多发，不仅是要动态地把指令归到若干个 slots 中，必要时还可以动态调整指令的执行顺序。例如</p> <pre><code class="language-asm">  ld x31, 20(x21)
  add x1, x31, x2
  sub x23, x23, x3
  andi x5, x23, 20
</code></pre> <p>可以把 <code class="language-plaintext highlighter-rouge">add</code> 和 <code class="language-plaintext highlighter-rouge">sub</code> 对换，在不影响功能的基础上规避了一个 bubble。</p> </li> <li> <p>动态多发基本框架</p> <p><img src="/assets/img/blog_post/co/cod-83.png" alt="cod-83" width="80%"/></p> <p>乱序执行，顺序 commit。</p> </li> </ul>]]></content><author><name></name></author><category term="CourseNotes"/><category term="Hardware"/><summary type="html"><![CDATA[Contains content about CPU design.]]></summary></entry><entry><title type="html">Computer Organization Note (Part 4 of 4)</title><link href="https://sqrtyz.github.io/blog/2024/CO-NOTE-4/" rel="alternate" type="text/html" title="Computer Organization Note (Part 4 of 4)"/><published>2024-01-01T12:00:00+00:00</published><updated>2024-01-01T12:00:00+00:00</updated><id>https://sqrtyz.github.io/blog/2024/CO-NOTE-4</id><content type="html" xml:base="https://sqrtyz.github.io/blog/2024/CO-NOTE-4/"><![CDATA[<h2 id="chapter-5-memory-hierarchy">Chapter 5 Memory Hierarchy</h2> <h3 id="introduction">Introduction</h3> <h4 id="transistor-晶体管">Transistor 晶体管</h4> <p><img src="/assets/img/blog_post/co/cod-84.png" alt="cod-84" width="80%"/></p> <p>类似于一个开关。栅极为 1 时两侧的 N 型半导体硅连通，input 连接到 output。</p> <h4 id="basic-memory-types">Basic Memory Types</h4> <ul> <li> <p>SRAM (Static Random Access Memory)</p> <p>六个晶体管。static 是指这种存储器只需要保持通电，里面的数据就可以永远保持。但是当断点之后，里面的数据仍然会丢失。</p> <p>SRAM 速度较快，但是成本更高，占用的空间更多。所以像诸如 CPU 的高速缓存，才会采用 SRAM。</p> <p><img src="/assets/img/blog_post/co/cod-85.png" alt="cod-85" width="40%"/></p> </li> <li> <p>DRAM (Dynamic Random Access Memory)</p> <p>一个电容加一个晶体管。由于 DRAM 使用电容存储，所以必须隔一段时间 refresh 一次，否则因为不断的微小漏电可能导致数据丢失。</p> <p>DRAM 速度较慢，但是成本更低。所以可以用于作为 main memory。</p> <p><img src="/assets/img/blog_post/co/cod-86.png" alt="cod-86" width="40%"/></p> </li> <li> <p>Disk Storage</p> <p><img src="/assets/img/blog_post/co/cod-98.png" alt="cod-98" width="80%"/></p> <ul> <li> <p>Structure</p> <ul> <li> <p><strong>Platter</strong> 盘子。一个磁盘一般有 4-16 个盘子。</p> </li> <li> <p><strong>Track</strong> 轨道。对应图上不同半径的环。</p> </li> <li> <p><strong>Sector</strong> 扇区。每个 track 又被分割为若干 sectors。</p> </li> <li> <p><strong>Cylinder</strong> 所有 platter 同一半径的 track 集合。</p> </li> <li> <p><strong>Read-write head</strong> 读写头。</p> </li> </ul> </li> <li> <p>Average Read Time of Disks</p> <p>基本方法为考虑四部分：</p> <ol> <li>寻道时间 Seek time</li> <li>旋转等待时间 Rotational latency</li> <li>数据传输时间 Transfer time</li> <li>控制用时 Control time</li> </ol> <p>【例题】Given 512B sector, 15,000 rpm, 4ms average seek time, 100MB/s transfer rate, 0.2ms controller overhead. Calculate average read time.</p> <ol> <li><strong>4ms</strong> seek time</li> <li>$\frac{1}{2} \times \frac{15000}{60}$ = <strong>2ms</strong> rotational latency（1/2 表示期望）</li> <li>$\frac{512B}{100MB/s}$ = <strong>0.005ms</strong> transfer time</li> <li><strong>0.2ms</strong> controller delay</li> </ol> <p>Total: <strong>6.2ms</strong></p> </li> </ul> </li> <li> <p>Flash Storage</p> <p>中文为闪存。比硬盘快了 100~1000 倍。Flash 又分为 NOR flash 和 NAND flash。</p> <p>我们熟知的 SSD（固态硬盘）一般就使用闪存存储数据。</p> </li> </ul> <h4 id="memory-hierarchy">Memory Hierarchy</h4> <p>Hierarchies bases on memories of different speeds and size.</p> <p>金字塔越往上，memory 更 expensive / small / fast。</p> <p><img src="/assets/img/blog_post/co/cod-87.png" alt="cod-87" width="90%"/></p> <h3 id="cache-basics">Cache Basics</h3> <h4 id="cache-intro---direct-mapped-cache">Cache Intro - Direct Mapped Cache</h4> <ul> <li> <p>基本思路</p> <p><img src="/assets/img/blog_post/co/cod-88.png" alt="cod-88" width="80%"/></p> <p><strong>(Cache Block Address)</strong> = <strong>(Memory Block Address)</strong> mod (Number of blocks in the cache)</p> <p>注意，一个 block 中不是一个 byte。RISC-V 中我们默认一个 block 的 <strong>最小大小</strong> 为 word (4 byte)。</p> <p>为了得知一个 cache block 中究竟存的是哪一个 memory block 的数据（例如上图中，一个灰色块可以对应 8 个灰色块），cache block 还会存下「其所存储的数据」对应的 memory block 地址的「高若干位」。具体地，一个 DMC 的结构如下所示：</p> </li> <li> <p>DMC 的结构</p> <p><img src="/assets/img/blog_post/co/cod-89.png" alt="cod-89" width="60%"/></p> <ol> <li> <p>V 表示 Valid bit，表示是否启用。启用为 1，反之为 0。</p> </li> <li> <p>Tag 即为刚刚所说的，「其所存储的数据」对应的 memory block 地址的「高若干位」。例如，对于上图例 Memory 中的最左边的灰色块，它的数据在 Cache 中存储在 001 的 Data 段，Tag 段对应为 00。</p> </li> <li> <p>Data 存储的就是数据。如果一个 block 的大小为 1 word，那么 Data 段的长度就是 32 位。</p> </li> </ol> </li> <li> <p>DMC 的寻址</p> <p>考虑一个情景，CPU 希望从内存中抓一个地址（记得是按 Byte 寻址哦）。这个 64 位的地址将会被分为 TAG / Index / Byte offset。其中 {Tag, Index} 联称 Memory Block Address。</p> <p>注意，当一个 block 包含 1 word 时，byte offset 占 2 位；但有时候一个 block 也可以占更多的字（比如 4 word），此时 byte offset 会占更多位（比如 4 位）。</p> <p><img src="/assets/img/blog_post/co/cod-90.png" alt="cod-90" width="80%"/></p> </li> </ul> <h4 id="cache-topic-1---block-placement">Cache Topic 1 - Block Placement</h4> <p><img src="/assets/img/blog_post/co/cod-91.png" alt="cod-91" width="80%"/></p> <p>除了 Direct Mapped，还有两种常见的映射策略：</p> <ul> <li> <p>Fully Associative</p> <p>内存中的 block 可以对到 cache 中的任何 block。好处是提高了 cache 的利用率，但是寻址会很麻烦。</p> </li> <li> <p>Set Associative</p> <p>介于 Direct Mapped 和 Fully Associative 之间。内存中的 block 可以对到 cache 中 <strong>某个 set</strong> 的任何 block。set 的选取和 block 一致，即 <strong>(Cache Set Address)</strong> = <strong>(Memory Block Address)</strong> mod <strong>(Number of sets in the cache)</strong></p> <p>对于 Set Associative，一个 set 如果包含 $k$ blocks，那么这个 cache 又被称为 $k$-way set associative。DM 和 FA 可以视作特殊的 SA。比如 DM 就是 $1$-way SA，FA 就是 $m$-way SA（其中 $m$ 表示 block 数目）。</p> </li> </ul> <h4 id="cache-topic-2---block-identification">Cache Topic 2 - Block Identification</h4> <p>基本思路就是按照 Direct Mapped 那样。</p> <p><img src="/assets/img/blog_post/co/cod-92.png" alt="cod-92" width="50%"/></p> <p>Direct Mapped 的具体寻址方式之前已经介绍。</p> <p>对于 Fully Associative，寻址方式如下：</p> <p><img src="/assets/img/blog_post/co/cod-93.png" alt="cod-93" width="70%"/></p> <p>对于 Set Associative，寻址方式如下：</p> <p><img src="/assets/img/blog_post/co/cod-94.png" alt="cod-94" width="80%"/></p> <h4 id="cache-topic-3---block-replacement">Cache Topic 3 - Block Replacement</h4> <p>如果一个 cache 满了，再从内存往里面放东西的话（例如 read miss），我们需要对其中的数据进行替代。</p> <ul> <li> <p>对于 Direct Mapped，没有这方面的担心。因为映射是多对一的，每次要么换要么不换。</p> </li> <li> <p>对于 Fully Associative 和 Set Associative，则需要考虑换掉哪个 block。一般有如下的策略：</p> <ol> <li> <p>Random replacement 字面意思，随机替换。</p> </li> <li> <p>Least-recently used (LRU) 最长时间没用的替换掉。</p> </li> <li> <p>First in, first out (FIFO) 队列思想，最早引入 cache 的替换掉。注意这和 LRU 不一样。</p> </li> </ol> </li> </ul> <h4 id="cache-topic-4---read-and-write-strategy">Cache Topic 4 - Read and Write Strategy</h4> <ul> <li> <p>Read Strategy</p> <ul> <li> <p>如果 Read hits，无事发生，这很好。</p> </li> <li> <p>如果 Read misses，我们需要执行一系列措施。实际上，Read misses 分为 instruction cache miss 和 data cache miss。以 instruction cache miss 为例：</p> <ol> <li> <p>将目前的 PC 值告诉 Memory，意思是我接下来要读 PC 对应的指令了，但是我在 Cache 部分没找到，所以要去 Memory 部分找。</p> </li> <li> <p>Memory access 到对应的 32 位指令。</p> </li> <li> <p>将对应的指令写进 instruction cache。其中 data 段放入指令本身，tag 段放入高位地址（ALU 来计算高位），valid bit 要设为 1。</p> </li> <li> <p>重启 PC 指令的 fetching，这次我们可以在 instruction cache 读取到它。</p> </li> </ol> </li> </ul> </li> <li> <p>Write Strategy</p> <ul> <li> <p>Write Hit Strategy</p> <ol> <li> <p>Write-back 只向缓存中写入数据，回头找个合适的时机写入内存。好处是很快，但是会导致数据的 inconsistent。</p> <p>此外，Write-back 不能直接丢弃 cached data（例如由 read miss 引起的替换），这是因为其中的值可能并未被同步到 memory。故而 cache 的 control bit 需要使用两位：valid bit【依然和原来一样，表示是否数据有效】和 dirty bit【表示是否同步到 memory 中，未同步则为 0】。如果替换时发现被替换者 dirty bit 为 0，则需要先将被替换者写入内存。</p> </li> <li> <p>Write-through 则同时向缓存和内存写入数据。好处是可以保证数据的 consistency，但是速度会较慢。</p> <p>对于 Write-through，我们可以放心地丢弃 cached data，因为其中的值和 memory 始终保持同步。此类 cache 的 control bit 只有 valid bit 一位。</p> </li> </ol> </li> <li> <p>Write Stall and Write Buffers</p> <p><strong>Write stall</strong> 指的是在 Write-through 中，CPU 必须等待 write to memory 完成所导致的 bubble。</p> <p><strong>Write buffer</strong> 如下图所示。对于 Write-through 的策略，由于理论上我们需要时刻把 cache 和 memory 保持同步，而这会耗费大量的时间。所以考虑 cache 同步到 memory 时，我们先把它写到一个 buffer 里面（这很快），写完后 CPU 继续干自己的活，buffer 则慢慢地把数据同步到 memory 中。</p> <p><img src="/assets/img/blog_post/co/cod-95.png" alt="cod-95" width="80%"/></p> </li> <li> <p>Write Miss Strategy</p> <ol> <li> <p>若 Write Hit Strategy 采取 Write-back，则 miss 时一般采取 Write allocate 策略（理论上也可以采取 Write around 策略）。</p> <p>Write allocate：<strong>如果 Write misses，先把对应的内存数据读到缓存中</strong>，转换为 Write hits 的情况再后续处理。</p> <p>注意，由于一个 block 可能包含若干个 word，所以我们也有必要这样做。考虑情景：本来一个 block 对应的 4 words 分别为 [A B C D]，考虑只写其中的一个 word。如果 write miss 发生，cache 中的对应 block 变为 [X E X X]（其中 [X X X X] 是对应 cache entry 的原始值），后面写到内存中，变为 [X E X X]，但实际上应该是 [A E C D]。</p> </li> <li> <p>若 Write Hit Strategy 采取 Write-through，则 miss 时一般采取 Write around 策略（理论上也可以采取 Write allocate 策略）。</p> <p>Write around：<strong>如果 Write misses</strong>，直接绕过 cache 把对应的数据写入 memory。想来确实也可以这么干。</p> </li> </ol> </li> </ul> </li> </ul> <h4 id="cache-memory-data-transfer">Cache-Memory Data Transfer</h4> <p>之前提到，如果发生 read miss 或者 write miss，则需要在 cache 与 memory 之间进行数据传输。对于不同的 Cache-Memory 结构，其传输效率也不一。</p> <p><img src="/assets/img/blog_post/co/cod-96.png" alt="cod-96" width="80%"/></p> <p>假设耗时（假设 Block size 为 4 words）：</p> <table> <thead> <tr> <th>Work</th> <th>CC Cost</th> </tr> </thead> <tbody> <tr> <td>send the address</td> <td>1</td> </tr> <tr> <td>DRAM access initiated</td> <td>15</td> </tr> <tr> <td>transfer a word of data</td> <td>1</td> </tr> <tr> <td>send the address</td> <td>1</td> </tr> </tbody> </table> <ol> <li> <p>One-word-wide memory organization</p> <p>最基本的架构。在以上假设下，读取一个 block 的耗时为 $1 + 4 \times (1+15)=65$ CC</p> </li> <li> <p>Wide memory organization</p> <p>更宽的总线和内存。在以上假设下，读取一个 block 的耗时为 $1 + (1+15)=17$ CC</p> <p>然而，随之而来的代价是硬件设计的要求提高（最直观的，占空间变多了）</p> </li> <li> <p>Interleaved memory organization</p> <p>内存分成几个 bank，这样一来内存部分可以同步进行 initialize。在以上假设下，读取一个 block 的耗时为 $1 + 4 \times 1 + 15=20$ CC</p> </li> </ol> <h3 id="measure-and-improve-cache-performance">Measure and Improve Cache Performance</h3> <h4 id="一些指标">一些指标</h4> <ul> <li> <p>Average Memory Assess Time (AMAT)</p> <p>= hit time + miss time</p> <p>= hit time + miss rate $\times$ miss penalty</p> </li> <li> <p>CPU Time (更新定义)</p> <p>= CPU execution clock cycles + Memory-stall clock cycles</p> </li> <li> <p>Memory-stall clock cycles</p> <p>= Number of instructions $\times$ miss rate $\times$ miss penalty</p> <p>(Also can be written as) = Read-stall cycles + Write-stall cycles</p> </li> <li> <p>Read-stall cycles</p> <p>= number of read instructions $\times$ read miss rate $\times$ read miss penalty</p> </li> <li> <p>Write-stall cycles <strong>(For Write-through strategy)</strong></p> <p>= number of write instructions $\times$ write miss rate $\times$ write miss penalty + write buffer stalls</p> </li> <li> <p>如果忽略 write buffer stalls，Read-stall cycles 和 Write-stall cycles 理论上可以合并。统一为</p> <p>Memory-stall clock cycles ＝ Memory access instructions $\times$ Miss rate $\times$ Miss penalty</p> </li> </ul> <h4 id="example-quiz">Example Quiz</h4> <p><img src="/assets/img/blog_post/co/cod-97.png" alt="cod-97" width="60%"/></p> <h4 id="miss-penalty-一图流">Miss Penalty 一图流</h4> <p><img src="/assets/img/blog_post/co/cod-99.png" alt="cod-99" width="80%"/></p> <h3 id="l1-and-l2-cache-hierarchy">L1 and L2 Cache Hierarchy</h3> <p>回顾之前的金字塔图，我们可以将 Cache 分为 L1 Cache 和 L2 Cache（两者均采用 SRAM，唯一的区别在于大小不同，L1 Cache 略快于 L2 Cache）。</p> <p>如果 L1 Cache miss 了，就去 L2 Cache 读取；如果再 miss，就去 DRAM。</p> <p>考虑这样一道计算题：</p> <ul> <li> <p>CPI of 1.0 on a 5GHz machine</p> </li> <li> <p>Initial: 2% miss rate, 100ns DRAM access</p> </li> <li> <p>Adding L2 Cache: 5ns access time, decreases miss rate to 0.5%</p> </li> </ul> <h3 id="virtual-memory">Virtual Memory</h3> <ul> <li> <p>Basic Concepts</p> <p>和之前印象中的 virtual memory 有点区别。似乎不是拿 disk 当 memory 用，据说 virtual memory 有很多所指。</p> <p>不管这些。我们接下来讨论的 virtual memory 实际上就是一个介于 CPU 和「实际地址」之间的「中介」。在实际过程中，CPU 只抛出虚拟地址，根据虚拟地址得到实际内存地址再去访问 cache memory (SRAM) / main memory (DRAM) / disk。</p> <p><img src="/assets/img/blog_post/co/cod-100.png" alt="cod-100" width="80%"/></p> </li> <li> <p>Fetching Physical Address Method I: Page Table</p> <p>一般来说 page table 位于 main memory 中，就像一般的内存那样存储了从 virtual address 到 physical address 的映射。</p> <p>如果某个数据不在 physical memory 中，则 virtual address 映射到的会是 disk address。此时称发生了 page fault，同时这会导致极大的 miss penalty。</p> <p><img src="/assets/img/blog_post/co/cod-101.png" alt="cod-101" width="70%"/></p> <p>下图展示了具体如何利用 page table 将 virtual address 映射到 physical address 的方法。前半部分拿进去查表，后半部分 offset 保持不变。当然，这只是 page table hit 的情况。</p> <p><img src="/assets/img/blog_post/co/cod-102.png" alt="cod-102" width="80%"/></p> </li> <li> <p>Fetching Physical Address Method II: TLB</p> <p>为了加速从 virtual address 找 physical address 这一过程，我们可以添加一个 TLB (Translation-lookaside Buffer) 模块。</p> <p>TLB 可以视作一个「关于 page table 的 fully-associative cache」。注意 TLB 只存储映射到 physical memory 的情形。</p> <p><img src="/assets/img/blog_post/co/cod-103.png" alt="cod-103" width="80%"/></p> </li> <li> <p>Whole Structure</p> <p>考虑 TLB 后，memory data 的获取流程如下（图中未显示 page table 的情形，不过应该比较好脑补）。</p> <p><img src="/assets/img/blog_post/co/cod-104.png" alt="cod-104" width="80%"/></p> <p><img src="/assets/img/blog_post/co/cod-105.png" alt="cod-105" width="80%"/></p> </li> <li> <p>理解检测</p> <p><img src="/assets/img/blog_post/co/cod-106.png" alt="cod-106" width="80%"/></p> </li> </ul> <h2 id="chapter-6-storage-networks-and-other-peripherals">Chapter 6 Storage, Networks and Other Peripherals</h2> <h3 id="introduction-1">Introduction</h3> <ul> <li> <p>Typical I/O Devices</p> <p><img src="/assets/img/blog_post/co/cod-107.png" alt="cod-107" width="80%"/></p> </li> <li> <p>Three Characters of I/O</p> <ol> <li> <p>Behavior</p> <p>行为。例如是做 input，还是 output，还是 storage。</p> </li> <li> <p>Partner</p> <p>对象。交互对象，例如 mouse 的 partner 是人，network 的 partner 是机器。</p> </li> <li> <p>Data Rate</p> <p>I/O device 和 main memory/processor 之间的数据传输速度峰值。</p> </li> </ol> </li> <li> <p>I/O Performance Measurement: <strong>Throughput</strong> and <strong>Response Time</strong></p> </li> </ul> <h3 id="disk-storage-and-dependability">Disk Storage and Dependability</h3> <ul> <li> <p>Availability Measurement</p> <ol> <li> <p>MTTF (Mean Time to Failure)</p> <p>平均故障时间。即一个部件期望的无故障运行时长。</p> </li> <li> <p>MTTR (Mean Time to Repair)</p> <p>平均修复时间。即一个部件发生故障后期望的修复所需时长。</p> </li> <li>MTBF (Mean Time Between Failures) = MTTF + MTTR</li> <li>Availability = MTTF / (MTTF + MTTR)</li> </ol> </li> <li> <p>Reliability Measurement</p> <p>考虑一个情景：我们能否使用非常多的小 disk 来组成大 disk，进而缩短 disk 和 CPU/Memory 之间的速度差距？</p> <p><img src="/assets/img/blog_post/co/cod-108.png" alt="cod-108" width="60%"/></p> <p>答案是否定的。因为 (MTTF of N disks) = (MTTF of 1 Disk) / N。如此设计会让 disk 的可靠性大幅下降。</p> <p>实际上 reliability 的衡量建立于 availability 的衡量之上：</p> <ol> <li> <p>AFR (annual failure rate) = percentage of devices to fail per year</p> <p>= (365 $\times$ 24) hours / MTTF in hours</p> </li> <li> <p>“nines of availability” per year (中间是 availability，右边是 meaning)</p> <p><img src="/assets/img/blog_post/co/cod-109.png" alt="cod-109" width="60%"/></p> </li> </ol> </li> <li> <p>Magnetic Disk</p> <p>详见 Chapter 5: Introduction: Basic Memory Type 部分。</p> </li> <li> <p>Flash Storage</p> <p>详见 Chapter 5: Introduction: Basic Memory Type 部分。</p> </li> <li> <p>RAID</p> <p><img src="/assets/img/blog_post/co/cod-110.png" alt="cod-110" width="60%"/></p> <p>DBS 部分已有介绍。这边只作简要补充。</p> <ul> <li> <p>RAID 0: No Redundancy (Skipped)</p> </li> <li> <p>RAID 1: Disk Mirroring/Shadowing (Skipped)</p> </li> <li> <p>RAID 2: Error Correction Code (Skipped, <em>UNUSED</em> now)</p> </li> <li> <p>RAID 3: Bit-Interleaved Parity Disk</p> <p><img src="/assets/img/blog_post/co/cod-113.png" alt="cod-113" width="50%"/></p> <p>其中 0, 1, 2, …, 23 是数据的实际顺序。但是每个方框只包含了一个 bit。</p> </li> <li> <p>RAID 4: Block-Interleaved Parity Disk</p> <p><img src="/assets/img/blog_post/co/cod-111.png" alt="cod-111" width="70%"/></p> <p>其中 0, 1, 2, …, 23 是数据的实际顺序。每个方框只包含了一个 block。</p> <p>【写入分析 1】一次 Logical Write 将会涉及到 2 次 Physical Read 和 2 次 Physical Write（如上右图所示）。</p> <p>【写入分析 2】对比 RAID 3 和 RAID 4 的 small writes（绿色部分示意，假设 8bit）。RAID 3 需要进行 4 次串行的「Main Disk + Parity Disk」的物理读取和写入（无法并行是因为 Parity Disk 在 4 次中都需要被访问）；而 RAID 4 由于 8bit 都位于 block 0 中，所以只需要一次「Main Disk + Parity Disk」的物理读取和写入。</p> </li> <li> <p>RAID 5: Block-Interleaved Distributed Parity Disk</p> <p><img src="/assets/img/blog_post/co/cod-112.png" alt="cod-112" width="80%"/></p> <p>其中 0, 1, 2, …, 23 是数据的实际顺序。</p> <p>【写入分析 3】这种分布式设计允许更为激进的并行写入。例如：我要 logical write D0 和 D5。对于 RAID 5，这 $2 \times 2$ 个 disks <strong>互不干扰</strong>，可以同时进行；但是对于 RAID 4，$P$ 校验位使用同一个 disk，logical write 必须分两波次进行。</p> </li> <li> <p>RAID 6: P + Q Redundancy</p> <p>在 RAID 5 的基础上，使用两个 Redundancy Disk。</p> </li> <li> <p>Comparison</p> <ol> <li>一般而言，RAID 3 比 RAID 4 更擅长长序列读取，RAID 4 比 RAID 3 更擅长小范围读取；</li> <li>RAID 3 在 small writes 上具有最低的 throughput；RAID 3. 4. 5 在 large writes 上具有几乎一致的 throughput。</li> </ol> </li> </ul> </li> </ul> <h3 id="buses">Buses</h3> <h4 id="buses-basics">Buses Basics</h4> <ul> <li> <p>Buses</p> <p>总线是多条线的组合，用于进行各模块之间的数据传输。</p> <p>分为 control lines 和 data lines，其中 data lines 可以传输地址和具体数据。</p> </li> <li> <p>Bus Transactions</p> <ol> <li> <p>Output 流程（CPU 指示内存向 devices 中写出数据）</p> <p><img src="/assets/img/blog_post/co/cod-114.png" alt="cod-114" width="80%"/></p> </li> <li> <p>Input 流程（CPU 指示内存从 devices 中读取数据）</p> <p><img src="/assets/img/blog_post/co/cod-115.png" alt="cod-115" width="70%"/></p> </li> </ol> </li> </ul> <h4 id="asynchronous-data-fetching-handshaking-protocol">Asynchronous Data Fetching: Handshaking Protocol</h4> <p>考虑一个情形：某个 I/O Device 希望从 memory 中读取数据。在「同步」和「异步」的情况下，读取方法有所差异。接下来介绍异步读取的「握手协议」：</p> <p><img src="/assets/img/blog_post/co/cod-116.png" alt="cod-116" width="90%"/></p> <p>橙色表示 I/O Device 的信号，黑色表示 memory 的信号。Ack 相当于一条辅助信号线，用于告诉对方「我收到了你的请求 / 回应」。</p> <ol> <li> <p>When memory sees the ReadReq line, it reads the address from the data bus, begin the memory read operation，then raises Ack to tell the device that the ReadReq signal has been seen.</p> </li> <li> <p>I/O device sees the Ack line high and releases the ReadReq data lines.</p> </li> <li> <p>Memory sees that ReadReq is low and drops the Ack line.</p> </li> <li> <p>When the memory has the data ready, it places the data on the data lines and raises DataRdy.</p> </li> <li> <p>The I/O device sees DataRdy, reads the data from the bus , and signals that it has the data by raising ACK.</p> </li> <li> <p>The memory sees Ack signals, drops DataRdy, and releases the data lines.</p> </li> <li> <p>Finally, the I/O device, seeing DataRdy go low, drops the ACK line, which indicates that the transmission is completed.</p> </li> </ol> <p>【例题】</p> <blockquote> <p>Assume: <strong>The synchronous bus</strong> has a clock cycle time of 50 ns, and each bus transmission takes 1 clock cycle. <strong>The asynchronous bus</strong> requires 40 ns per handshake. The data portion of both buses is 32 bits wide.</p> <p>Question: Find the <strong>bandwidth</strong> for each bus when reading one word from a 200-ns memory.</p> </blockquote> <ul> <li> <p>Synchronous Case</p> <ol> <li>Send the address to memory : 50ns</li> <li>Read the memory : 200ns</li> <li>Send the data to the device : 50ns</li> </ol> <p>Thus, the total time is 300 ns. So, the bandwidth = 4bytes/300ns = 13.3MB/s</p> </li> <li> <p>Asynchronous Case</p> <p>回顾之前的握手协议图。</p> <p>Step 1: 40ns</p> <p>Step 2, 3, 4: $\max$(2 $\times$ 40ns + 40ns, 200ns) = 200ns</p> <p>Step 5, 6, 7: 3 $\times$ 40ns = 120ns</p> <p>所以读取一个 word 的总时间为 $360\text{ns}$。转换成带宽即为 $11.1$ MB/s。</p> </li> </ul> <h4 id="bus-arbitration">Bus Arbitration</h4> <p>当总线被多个 I/O Device 申请使用时，需要有人完成调度。一般承担这个工作的是 processor。</p> <p>四个常见的调度模式：</p> <ul> <li>daisy chain</li> <li>centralized</li> <li>self selection</li> <li>collision detection</li> </ul> <h4 id="bus-bandwidth-computation">Bus Bandwidth Computation</h4> <ul> <li> <p>例题</p> <p><img src="/assets/img/blog_post/co/cod-117.png" alt="cod-117" width="80%"/></p> <p>Suppose we have a system with the following characteristic:</p> <ol> <li> <p>A memory and bus system supporting block access of (4~16) 32-bit words.</p> </li> <li> <p>A 64-bit synchronous bus clocked at 200 MHz, with each 64-bit transfer taking 1 clock cycle, and 1 clock cycle required to send an address to memory.</p> </li> <li> <p>Two clock cycles needed between each bus transaction.（每次利用总线读取一个 block 视作一个 transaction，每个 transaction 之间需要空 2 个周期）</p> </li> <li> <p>A memory access time for the first four words of 200ns; each additional set of four words can be read in 20 ns. Assume that a bus transfer of the most recently read data and a read of the next four words can be overlapped.</p> </li> </ol> <p>Q1. Find the <strong>sustained bandwidth</strong> and the latency for a read of 256 words for transfers that use <strong>4-word blocks</strong> and for transfers that use <strong>16-word blocks</strong>.</p> <p>Q2. Also compute <strong>effective number of bus transactions</strong> per second for each case.</p> </li> <li> <p>解答（4-word block case）</p> <p>For each block, it takes</p> <ol> <li><strong>1 CC</strong> to send the address to memory</li> <li>200ns/(5ns/cycle) = <strong>40 CC</strong> to read memory</li> <li><strong>2 CC</strong> to send the data from the memory</li> <li><strong>2 CC</strong> needed between each bus operation.</li> </ol> <p>This is a total of <strong>45 CC</strong>.</p> <p>Since there are 256/4 = 64 blocks, the transfer of 256 words takes 45 $\times$ 64 = 2880 CC.</p> <p>The latency for the transfer of 256 words is: 2880 cycles $\times$ (5ns/cycle) = 14,400 ns.</p> <p>Final answer:</p> <ul> <li> <p>Number of bus transactions per second:</p> <p>$64 \text{ transactions} \times \frac{1 \text{second}}{14,400 \text{ns}} = 4.44 \text{M transactions/s}$.</p> <p>注意，当使用 4-word block 进行传输时，一次 256-word transfer 实际上包含了 64 次 bus transactions。</p> </li> <li> <p>Bandwidth</p> <p>$1024 \text{bytes} \times \frac{1 \text{second}}{14,400 \text{ns}} = 71.11 \text{ MB/s}$.</p> </li> </ul> </li> <li> <p>解答 (16-word block case)</p> <p>For each block, it takes</p> <ol> <li><strong>1 CC</strong> to send the address to memory</li> <li>260ns/(5ns/cycle) = <strong>52 CC</strong> to read memory</li> <li><strong>2 CC</strong> to send the data from the memory <strong>(Overlap Considered)</strong></li> <li><strong>2 CC</strong> needed between each bus operation.</li> </ol> <p>This is a total of <strong>57 CC</strong>.</p> <p>Since there are 256/16 = 16 blocks, the transfer of 256 words takes 57 $\times$ 16 = 912 CC.</p> <p>The latency for the transfer of 256 words is: 912 cycles $\times$ (5ns/cycle) = 4,560 ns.</p> <p>Final answer:</p> <ul> <li> <p>Number of bus transactions per second:</p> <p>$16 \text{ transactions} \times \frac{1 \text{second}}{4,560 \text{ns}} = 3.51 \text{M transactions/s}$.</p> </li> <li> <p>Bandwidth</p> <p>$1024 \text{bytes} \times \frac{1 \text{second}}{4,560 \text{ns}} = 224.56 \text{ MB/s}$.</p> </li> </ul> </li> </ul> <h3 id="interfacing-io-devices-to-the-memory-processor-and-os">Interfacing I/O Devices to the Memory, Processor, and OS</h3> <ul> <li> <p>I/O Characteristics</p> <ol> <li>(shared) 被多个程序共享</li> <li>(interrupts) 使用中断进行交互</li> <li>(complex) 底层控制非常复杂</li> </ol> </li> <li> <p>I/O Communication Types</p> <ol> <li>由 OS 发出指令给到 I/O devices（注意不是硬件）</li> <li>I/O devices 相应指令（无论是否成功完成操作）</li> <li>数据传输，必须发生在 I/O devices 和 memory 之中</li> </ol> </li> <li> <p>How to Give Commands to I/O Devices?</p> <p>【Method 1】Memory-Mapped I/O</p> <p>一种巧妙的设计，即每个 I/O 都与某个内存地址建立映射。当需要访问某个 I/O 时，直接用 <code class="language-plaintext highlighter-rouge">lw</code> 或 <code class="language-plaintext highlighter-rouge">sw</code> 等指令访问对应的 I/O 即可。</p> <p>【Method 2】Special I/O Instructions</p> <p>指令集为 I/O 专门设计的指令。例如 <code class="language-plaintext highlighter-rouge">in al, port</code> 和 <code class="language-plaintext highlighter-rouge">out port, al</code> 等。</p> </li> <li> <p>Communication with Processor</p> <ol> <li> <p><strong>Polling（轮寻）</strong>：定期（如每 10ms）去寻访某个 I/O，看其在过去的 10ms 内有无 I/O 请求。若有则执行。</p> </li> <li> <p><strong>Interrupt（中断）</strong>：当某个 I/O 发出请求，立刻中断 processor 并赶去执行。</p> <p><img src="/assets/img/blog_post/co/cod-118.png" alt="cod-118" width="80%"/></p> <p>从上图可以看出，为了 incept data，printer 会抛出 request interrupt。</p> <p>而每当 printer 抛出一个 request interrupt，都会导致 CPU 产生一个中断（对应 response interrupt），并在这个中断中为 printer 传输数据。</p> </li> <li> <p><strong>Direct Memory Access (DMA)</strong>：</p> <p>实际上是 Interrupt 下的一个子分支，不过加入了 DMA 的优化。简单理解为，CPU 创建了一个专门处理 I/O 事件的「小跟班」DMA。</p> <p>以往 I/O Device 想要和 memory 交互（获取数据），必须要经过 CPU（这是因为 CPU 才能控制 memory）。而这会导致 CPU 被频繁中断，不好。</p> <p>优化后，在某一批次的 I/O 之前，CPU 事先创建并初始化一个 DMA，使其代为执行自己职责。这样只有在这一批 I/O 开始和结尾会导致 CPU 产生中断（共计 2 次，少了很多）。</p> <p><img src="/assets/img/blog_post/co/cod-119.png" alt="cod-119" width="60%"/></p> </li> </ol> </li> <li> <p>Measure the Performance of Polling / Interrupt / DMA</p> <ol> <li> <p>Polling</p> <ul> <li> <p>Question:</p> <p><img src="/assets/img/blog_post/co/cod-120.png" alt="cod-120" width="60%"/></p> </li> <li> <p>Solution:</p> </li> </ul> <p><img src="/assets/img/blog_post/co/cod-121.png" alt="cod-121" width="60%"/></p> </li> <li> <p>Interrupt</p> <ul> <li> <p>Question:</p> <p>Suppose we have the same hard disk and processor we used in the former example, but we used interrupt-driven I/O. The overhead for each transfer, including the interrupt, is 500 clock cycles. Find the fraction of the processor consumed if <strong>the hard disk is only transferring data 5% of the time</strong>.</p> </li> <li> <p>Solution:</p> <p>实际上，最后一句话的假设是使得 Interrupt 在绝大多数情况下效率高于 Polling 的根本原因。考虑一个较长的时间段，比如说 1s。在此期间有 0.05s 我们进行 hard-disk I/O。这 0.05s 内我们需要传输 $0.05 \times 4 \text{MB} = 200 \text{KB}$ 数据。一次 data transfer 为 $16 \text{B}$，所以总共会造成 $12,500$ 次中断，损失 $12,500 \times 500 = 6.25 \times 10^6 \text{CC}$。</p> <p>一秒钟共 $500 \times 10^6 \text{CC}$，所以损失率为 $1.25\%$。</p> </li> </ul> </li> <li> <p>DMA</p> <ul> <li> <p>Question:</p> <p>Suppose we have the same hard disk and processor we used in the former example.</p> <p>Assume that the initial setup of a DMA transfer takes 1000 clock cycles for the processor, and assume the handling of the interrupt at DMA completion requires 500 clock cycles for the processor.</p> <p>The hard disk has a transfer rate of 4MB/sec and uses DMA. The average transfer from disk is 8 KB.<em>（这里的意思是，每次 transfer 的数据量大小 8KB。每次 transfer 之间可能相隔较久，所以需要重新初始化 DMA）</em> Assume the disk is actively transferring 100% of the time.</p> <p>Please find what fraction of the processor time is consumed.</p> </li> <li> <p>Solution:</p> <p>一次 disk transfer 所需时间为 8KB / (4MB / s) = 2ms。</p> <p>由于假设所有时间都在做 disk I/O，所以相当于 1s 内会做 500 批 disk I/O。</p> <p>每批 disk I/O 需要重新建立 DMA，同时打断 CPU，这部分总共消耗 1500 CC。</p> <p>所以 1s 内会使得 CPU 中断 $7.5 \times 10^5 \text{CC}$。损失率为 $0.2\%$。</p> </li> </ul> </li> </ol> </li> </ul>]]></content><author><name></name></author><category term="CourseNotes"/><category term="Hardware"/><summary type="html"><![CDATA[Contains content about memory and hierarchy storage.]]></summary></entry><entry><title type="html">Information Theory Note (Part 1 of 2)</title><link href="https://sqrtyz.github.io/blog/2024/IT-NOTE-1/" rel="alternate" type="text/html" title="Information Theory Note (Part 1 of 2)"/><published>2024-01-01T12:00:00+00:00</published><updated>2024-01-01T12:00:00+00:00</updated><id>https://sqrtyz.github.io/blog/2024/IT-NOTE-1</id><content type="html" xml:base="https://sqrtyz.github.io/blog/2024/IT-NOTE-1/"><![CDATA[<h2 id="chapter-1-信息的度量">Chapter 1 信息的度量</h2> <h3 id="lec-1-随机变量的熵和互信息">Lec 1 随机变量的熵和互信息</h3> <h4 id="11-自信息">1.1 自信息</h4> <p>对于概率空间 $\{X,\mathcal{X},p(x)\}$，事件 $\{X=x_k\}$ 的 <strong>自信息</strong> 定义为</p> \[I(x_k)=-\log_ap(x_k)\] <p>当 $a=2$，为比特（bit）。当 $a=e$，为奈特（nat）。</p> <ul> <li> <p>自信息的理解</p> <ol> <li>事件发生后对观察者提供的信息量；</li> <li>观察者为确证该事件所需要付出的代价（类比功与能量）；</li> <li>事件的自信息并不代表事件的不确定性，事件本身没有不确定性可言。</li> </ol> </li> </ul> <p>例如，$p(x_k)=1$ 时，$I(x_k)=0$：「明天太阳从东边升起。」这句话没有信息量。</p> <h4 id="12-条件自信息两事件的互信息">1.2 条件自信息、两事件的互信息</h4> <ul> <li> <p>条件自信息</p> <p>对于二维随机变量概率空间 $\{(X,Y),\mathcal{X \times Y}, p(x,y)\}$，事件 $\{Y=y_j\}$ 发生的条件下事件 $\{X=x_k\}$ 的 <strong>条件自信息</strong> 定义为</p> \[I(x_k|y_j)=-\log p(x_k|y_j)\] <p>本质是已知 $\{Y=y_j\}$ 发生的情况下，突然 $\{X=x_k\}$ 又发生了，这件事情所提供给观察者的信息量。</p> </li> <li> <p>互信息</p> <p>概率空间 $\{(X,Y),\mathcal{X \times Y}, p(x,y)\}$，事件 $\{Y=y_j\}$ 与事件 $\{X=x_k\}$ 的 <strong>互信息</strong> 定义为</p> \[I(x_k;y_j)=I(x_k)-I(x_k|y_j)= - \log p(x_k) + \log p(x_k|y_j)\] <p>本质是事件 $\{Y=y_j\}$ 发生后对 $\{X=x_k\}$ 的不确定性的降低。</p> <p>互信息具有对称性！$I(x_k;y_j)=I(y_j;x_k)$，从定义出发加贝叶斯定理证明即可。</p> </li> </ul> <h4 id="13-多事件下的概念拓展">1.3 多事件下的概念拓展</h4> <ul> <li> <p>联合自信息</p> <p>概率空间 $\{(X,Y),\mathcal{X \times Y}, p(x,y)\}$，事件 $\{Y=y_j\}$ 与事件 $\{X=x_k\}$ 的 <strong>联合自信息</strong> 定义为</p> \[I(x_k,y_j)= - \log p(x_k,y_j)\] </li> <li> <p>条件互信息</p> <p>给定 $Z=z$ 的条件下，$X=x$ 与 $Y=y$ 之间的条件互信息为（<code class="language-plaintext highlighter-rouge">,</code> 优先级大于 <code class="language-plaintext highlighter-rouge">|</code>）</p> \[I(x;y|z)= - \log p(x|z) + \log p(x|y,z)\] <p>其含义为 $Z=z$ 发生时，$X=x$ 和 $Y=y$ 相互之间提供的信息量。依然具有对称性。</p> </li> <li> <p>联合互信息</p> <p>联合事件 $\{Y=y,Z=z\}$ 和事件 $\{X=x\}$ 之间的互信息为</p> \[I(x;y,z)= - \log p(x) + \log p(x|y,z)\] <p>其含义为 $\{Y=y,Z=z\}$ 联合提供给 $\{X=x\}$ 的信息量。</p> </li> <li> <p>事件联合互信息的链式法则</p> \[I(x;y,z)=I(x;y)+I(x;z|y)\] <p>事件 $\{Y=y,Z=z\}$ 联合提供给 $\{X=x\}$ 的信息量等于【$\{Y=y\}$ 提供给 $\{X=x\}$ 的信息量】加上【$\{Y=y\}$ 已知情况下，$\{Z=z\}$ 提供给 $\{X=x\}$ 的信息量】。</p> <p><img src="/assets/img/blog_post/it/it-1.png" alt="it-1" width="50%"/></p> </li> </ul> <h4 id="14-随机变量的熵">1.4 随机变量的熵</h4> <p>熵的定义即为平均自信息（自信息的期望值）。</p> \[H(X)=E[I(X)]=\sum_{x \in \mathcal{X}} p(x) I(x)=-\sum_{x \in \mathcal{X}} p(x) \log p(x)\] <p>【熵与自信息的区别】熵针对的是随机变量 $X$，自信息针对的是具体事件 $\{X=x\}$。</p> <p>【例子】对于伯努利分布 $X \sim B(p)$，$H(X) = -p \log p - (1-p) \log (1-p)$。当 $p=0 / 1$ 时，熵为 $0$；当 $p=0.5$ 时，熵取到最大值。</p> <p>【理解】熵是随机变量不确定性的度量。</p> <h4 id="15-关于熵的衍生概念">1.5 关于熵的衍生概念</h4> <ul> <li> <p>联合熵</p> \[H(X,Y)=E[I(X,Y)]=-\sum_{x \in \mathcal{X}, y \in \mathcal{Y}} p(x,y) \log p(x,y)\] <p>表达了两个变量的不确定度。</p> </li> <li> <p>条件熵</p> <p><strong>定义 1</strong>：给定 $Y=y$ 条件下，$X$ 的条件熵为</p> \[H(X|y)=-\sum_{x \in \mathcal{X}} p(x|y) \log p(x|y)\] <p>注意 $Y=y$ 是已然发生的。</p> <p><strong>定义 2</strong>：随机变量 $X$ 相对于随机变量 $Y$ 的条件熵为</p> \[H(X|Y) = E[H(X|y)] = -\sum_{y \in \mathcal{Y}} p(y) \sum_{x \in \mathcal{X}} p(x|y) \log p(x|y) = -\sum_{y \in \mathcal{Y}}\sum_{x \in \mathcal{X}} p(x,y) \log p(x|y)\] <table> <tbody> <tr> <td>当 $X,Y$ 统计独立时，有 $H(X</td> <td>Y)=H(X)$。</td> </tr> </tbody> </table> </li> <li> <p>随机变量联合熵的链式法则【HD】</p> \[H(X,Y)=H(X)+H(Y|X)=H(Y)+H(X|Y)\] <p>Proof:</p> <p><img src="/assets/img/blog_post/it/it-2.png" alt="it-2" width="50%"/></p> <p>无论什么情况，这个式子都成立。</p> <table> <tbody> <tr> <td>特别地，当 $X,Y$ 统计独立时，有 $H(X</td> <td>Y)=H(X)$，此时 $H(X,Y)=H(X)+H(Y)$。</td> </tr> </tbody> </table> </li> </ul> <h4 id="16-熵的性质">1.6 熵的性质</h4> <ul> <li> <p>基本性质</p> <p><img src="/assets/img/blog_post/it/it-3.png" alt="it-3" width="50%"/></p> </li> <li> <p>可加性（分步观察）</p> <p>考虑如下的决策树情景：</p> <p><img src="/assets/img/blog_post/it/it-4.png" alt="it-4" width="50%"/></p> <p>对于变量 $X$（注意本质上只有一个变量）可以进行 <strong>多步观察</strong>，每一步的观察可以从上一步的观察得到更细致的结果。变量 $X$ <strong>在最后的观察结果集合中的不确定性</strong> 等于【第一次观察结果的不确定性】加上【其后每次观察结果在前一次观察结果已知的前提下的不确定性】。</p> <p><em>和链式法则记得区分！</em></p> <p>可加性的证明：</p> <p><img src="/assets/img/blog_post/it/it-5.png" alt="it-5" width="50%"/></p> <p>在如此的分步观察下，有</p> \[H(X_1,X_2)=H(X_2)+H(X_1|X_2)=H(X_2)\] \[H(X_1,X_2)=H(X_1)+H(X_2|X_1)=H(X_2)\] <p>注意这个式子只有在上上图所示的决策树情形才适用。</p> <table> <tbody> <tr> <td>注意第一个式子意味着 $H(X_1</td> <td>X_2)=0$。回顾上上图，这是因为当 $X_2$ 确定时（例如 $A_2$），$X_1$ 也随之确定（例如 $A$）。所以条件熵为零。反之则没有这个性质。</td> </tr> </tbody> </table> </li> <li> <p>极值性</p> \[H_K(p_1,p_2,\cdots,p_K) \leq H_K(\frac{1}{K},\frac{1}{K},\cdots,\frac{1}{K}) = \log K\] <p>极值性的证明：</p> <p><img src="/assets/img/blog_post/it/it-6.png" alt="it-6" width="50%"/></p> </li> <li> <p>条件熵 $\leq$ 熵：增加条件使熵减小</p> \[H(X|Y) \leq H(X)\] <p>注意 $Y$ 不是已知的。当 $\{Y=y\}$ 时两者的关系是不确定的。证明如下（第一行用了上一个证明的引理）。</p> <p><img src="/assets/img/blog_post/it/it-7.png" alt="it-7" width="50%"/></p> </li> <li> <p>凸性</p> <p>熵具有一个很优美的性质，它是凸的。</p> <p><img src="/assets/img/blog_post/it/it-10.png" alt="it-10" width="50%"/></p> <p>相比于一般的凸函数，概率空间上的函数还要求 $\sum\limits_{i=1}^np_i=1$。根据拉格朗日乘数法，对于概率空间上的上凸函数 $\alpha$，要使 $f(\alpha)$ 取得最大值，则 $f(\alpha)-\lambda(\sum\alpha_i-1)$ 取得最大值。</p> <p><img src="/assets/img/blog_post/it/it-11.png" alt="it-11" width="50%"/></p> </li> </ul> <h4 id="17-平均互信息和熵">1.7 平均互信息和熵</h4> <p>回顾互信息的概念</p> \[I(x;y)=I(x)-I(x|y)= - \log p(x) + \log p(x|y) = \log \frac{p(x|y)}{p(x)}\] <table> <tbody> <tr> <td>平均互信息定义为其期望，即 $I(X;Y)=\sum\limits_x\sum\limits_y p(x,y)\log \frac{p(x</td> <td>y)}{p(x)}$。</td> </tr> </tbody> </table> <ul> <li> <p>平均互信息和熵的关联</p> <p>注意到</p> \[I(X;Y)=\sum\limits_x\sum\limits_y p(x,y) \log \frac{p(x|y)}{p(x)}\] \[I(X;Y)=\sum\limits_x\sum\limits_y p(x,y) \log {p(x|y)} - \sum\limits_x\sum\limits_y p(x,y){p(x)}\] \[I(X;Y)=H(X)-H(X|Y) \ (I)\] <p>显然平均互信息具有对称性</p> \[I(X;Y)=H(Y)-H(Y|X) \ (II)\] <p>代入联合熵的链式法则，还有</p> \[I(X;Y)=H(X)+H(Y)-H(X,Y) \ (III)\] <p>I, II, III 整理一下即可得到下图【IMPORTANT】：</p> <p><img src="/assets/img/blog_post/it/it-8.png" alt="it-8" width="50%"/></p> <p>可以证明，平均互信息是 <strong>非负的</strong>。给定额外的信息，至少不会让熵增加。</p> <p><img src="/assets/img/blog_post/it/it-9.png" alt="it-9" width="50%"/></p> </li> </ul> <h4 id="18-相对熵散度">1.8 相对熵（散度）</h4> <p><img src="/assets/img/blog_post/it/it-12.png" alt="it-12" width="50%"/></p> <p><img src="/assets/img/blog_post/it/it-13.png" alt="it-13" width="50%"/></p> <h4 id="19-关于疑义度的-fano-不等式">1.9 关于疑义度的 Fano 不等式</h4> <p>定义在相同字符表 $\{0,1,\cdots,K\}$ 上的两个随机变量 $X$ 和 $\hat{X}$，其中 $\hat{X}$ 是对 $X$ 的某种估计。估计错误概率定义为</p> \[P_E=\sum\limits_{i=0}^{K-1}\sum\limits_{j=0,j \neq i}^{K-1} P \\{X=i,\hat{X}=j\\}\] <p>则 $\hat{X}$ 已知条件下 $X$ 的 <strong>疑义度</strong> 满足表达式</p> \[H(X|\hat{X})\le H(P_E,1-P_E)+P_E \log (K-1)\] <p>证明如下：</p> <p><img src="/assets/img/blog_post/it/it-14.png" alt="it-14" width="50%"/></p> <p>注意其中的 $H(P_E)$ 实际上从定义上就是 $H(E)$ ($E=1$ when $X \neq \hat{X}$)。感觉直接写成 $H(P_E)$ 不是很严谨。</p> <table> <tbody> <tr> <td>它的物理意义是，如果建立了关于 $X$ 的某种估计 $\hat{X}$，并且已知其错误率 $P_E$，那么我们可以知道这中估计有多可靠（根据 $H(X</td> <td>\hat{X})$ 判断）。例如，假设 $K=2,P_E=1$，你会发现这个疑义度为 $0$。</td> </tr> </tbody> </table> <h4 id="110-互信息的凸性">1.10 互信息的凸性</h4> <table> <tbody> <tr> <td>显然，$I(X;Y)$ 的值和概率分布 $p(X)$ 和转移概率分布矩阵 $p(Y</td> <td>X)$ 直接相关。</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>当转移概率分布矩阵 $p(Y</td> <td>X)$ 固定时，$I(X;Y)$ 是 $p(X)$ 的上凸函数。</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>当输入分布矩阵 $p(X)$ 固定时，$I(X;Y)$ 是 $p(Y</td> <td>X)$ 的下凸函数。</td> </tr> </tbody> </table> <h3 id="lec-2-连续随机变量的互信息微分熵">Lec 2 连续随机变量的互信息、微分熵</h3> <h4 id="21-定义连续随机变量的互信息">2.1 定义：连续随机变量的互信息</h4> <p><img src="/assets/img/blog_post/it/it-15.png" alt="it-15" width="50%"/></p> <h4 id="22-定义微分熵">2.2 定义：微分熵</h4> <ul> <li> <p>基本定义</p> <p><img src="/assets/img/blog_post/it/it-16.png" alt="it-16" width="50%"/></p> <p>如果按照离散的方法对微分熵进行定义，会发现直接飙到正无穷。</p> <p>所以采取了上图中下面的那个定义方法，即</p> \[H_C(X)=h(X) \triangleq-\int p_X(x) \log p_X(x) dx\] </li> <li> <p>条件微分熵、联合微分熵</p> <p><img src="/assets/img/blog_post/it/it-17.png" alt="it-17" width="50%"/></p> </li> <li> <p>一个关于微分熵的例子</p> <blockquote> <p>已知某线段的长度在 $[0,L]$ 之间均匀分布，现用精度为 $\Delta$ 的尺子去量它，问量得的结果对于线段的真实长度提供多少信息？</p> </blockquote> <p>令：$X=$ 线段的长度，$Y=$ 测量的结果。</p> <table> <tbody> <tr> <td>测量前 $H_C(X)=\log L$，测量后 $H_C(X</td> <td>Y)=\log \Delta$</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>故而 $I(X;Y)=H_C(X)-H_C(X</td> <td>Y)=\log\frac{L}{\Delta}$。</td> </tr> </tbody> </table> </li> </ul> <h4 id="23-微分熵的性质">2.3 微分熵的性质</h4> <ul> <li> <p>线性变化下不具有不变性</p> <p>对于离散随机变量，若存在一一映射 $X \to Y$，则有 $H(X)=H(Y)$。</p> <p>但对于连续随机变量，即使有一一映射，甚至即使是线性的，这种关系也不存在。</p> </li> <li> <p>均匀分布的微分熵</p> <p>设 $p(x)=\frac{1}{b-a}, x \in [a,b]$。$H_C(X)=\int_a^b \frac{1}{b-a} \ln (b-a) d x=\ln (b-a)$。</p> </li> <li> <p>微分熵的极大化：峰值受限</p> <p>设 $X$ 取值于 $(-M,M)$，即 $\int_{-M}^{M}p(x)dx=1$，这时微分熵 $H_C(X) \le \ln 2M$，等号在 <strong>均匀分布</strong> 时取到。</p> <p>使用拉格朗日乘数法证明。</p> \[\begin{aligned} &amp; J(p(x)) \triangleq H_C(X)-\lambda \int_{-M}^{+M} p(x) d x \newline &amp; =-\int_{-M}^{+M} p(x) \ln p(x) d x-\lambda \int_{-M}^{+M} p(x) d x \newline &amp; =-\int_{-M}^{+M} p(x) \ln \left(e^\lambda p(x)\right) d x \newline &amp; \leq-\int_{-M}^{+M} p(x)\left(1-\frac{1}{e^\lambda p(x)}\right) d x \newline &amp; =\frac{2 M}{e^\lambda}-1=\text { const. } \end{aligned}\] <p>等号成立的条件为 $p(x)=e^{-\lambda}=\text{const}$，亦即均匀分布。</p> <p>根据约束条件 $\int_{-M}^{M}p(x)dx=1$ 知 $p(x)=\frac{1}{2M}$，所以 $H_C(X) \le \ln 2M$。</p> </li> <li> <p>微分熵的极大化：平均功率受限</p> <p>在方差 $\sigma^2$ 一定的条件下，当 $X$ 服从 <strong>正态分布</strong> 时微分熵最大。即 $H_C(X) \le \ln (\sqrt{2\pi e}\sigma)$。</p> </li> </ul> <h3 id="lec-3-平稳离散信源的熵">Lec 3 平稳离散信源的熵</h3> <h4 id="31-平稳随机过程">3.1 平稳随机过程</h4> <p>对于 <strong>任意</strong> 的 $n$，任意的 $t_1, t_2, \cdots, t_n \in T$ 和 $h$，</p> <p>若 $(X(t_1),X(t_2),\cdots,X(t_n))$ 与 $(X(t_1+h),X(t_2+h),\cdots,X(t_n+h))$ 具有同样的分布，则称随机过程 $\{X(t)\}$ 是平稳随机过程。</p> <ul> <li> <p>平稳随机过程的性质</p> <p>$E(X(t_n))=E(X(t_n+h))=E(X(0))=Const$</p> <p>对于所有 $t$，$X(t)$ 的均值和方差一致。</p> <p>值得指出的是，平稳随机并不意味着 $X(t_i)$ 和 $X(t_j)$ 分布是独立的。</p> </li> </ul> <h4 id="32-平稳信源">3.2 平稳信源</h4> <ul> <li> <p>平稳信源的定义</p> <p>类比平稳随机过程，平稳信源意味着任意长度片段的联合概率分布和时间起点无关。即</p> \[P(X_1,X_2,\cdots,X_L)=P(X_{1+n},X_{2+n},\cdots,X_{L+n})\] <p>在平稳信源的基础上，有两种条件更为苛刻的信源：</p> <ol> <li> <p>$m$ 阶马尔可夫信源</p> \[P(X_l|X_{l-1},X_{l-2},\cdots,X_0)=P(X_l|X_{l-1},X_{l-2},\cdots,X_{l-m})\] <p>即，$X_l$ 的分布只会受到 $X_{l-1} \sim X_{l-m}$ 的影响。</p> <p>当 $m=1$ 时，又称马尔可夫信源。</p> </li> <li> <p>简单无记忆信源</p> <p>不同时间的随机变量无关。即 $P(X_1,X_2,\cdots,X_L)=\prod_{i=1}^L P(X_i)$。</p> <p>似乎可以看成 $m=0$ 的马尔可夫信源？</p> </li> </ol> </li> <li> <p>平稳信源的熵</p> <p>如果一个平稳信源发出长度为 $n$ 的序列 $X_1,X_2,\cdots,X_n$，记 $n$ 维随机矢量 $X=(X_1,X_2,\cdots,X_n)$，则定义</p> \[H(X)=H(X_1,X_2,\cdots,X_n)=-\sum p(x_1,x_2,\cdots,x_n) \log p(x_1,x_2,\cdots,x_n)\] <p>其实就是把熵的定义给搬到了很多元的矢量情况，不过矢量各分量之间有所关联。显然 $H(X)$ 随着 $n$ 的增大而增长，趋向无穷大。</p> <p>定义以下子概念：</p> <ol> <li> <p>平均每符号熵（平均值）：$H_n(X) = \frac{1}{n}H(X) = \frac{1}{n}H(X_1,X_2,\cdots,X_n)$</p> </li> <li> <p>熵速率：$H_\infty(X) = \lim\limits_{n \to \infty} H_n(X)$</p> </li> <li> <table> <tbody> <tr> <td>平均条件熵：$H(X_n</td> <td>X_{n-1},X_{n-2}, \cdots, X_1)$</td> </tr> </tbody> </table> </li> </ol> </li> <li> <p><strong>平稳信源熵的性质</strong> （以下性质不需要求信源满足无记忆 / 马尔可夫）</p> <p><img src="/assets/img/blog_post/it/it-18.png" alt="it-18" width="50%"/></p> <ol> <li> <table> <tbody> <tr> <td>平均条件熵 $H(X_n</td> <td>X_{n-1},X_{n-2}, \cdots, X_1)$ 非严格递减</td> </tr> </tbody> </table> </li> <li> <p>平均每符号熵 $H_n(X)$ 非严格递减</p> </li> <li> <table> <tbody> <tr> <td>$H_n(X) \ge H(X_n</td> <td>X_{n-1},X_{n-2}, \cdots, X_1)$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>$H_\infty(X) = \lim\limits_{n \to \infty} H_n(X) = \lim\limits_{n \to \infty} H(X_n</td> <td>X_{n-1},X_{n-2}, \cdots, X_1)$</td> </tr> </tbody> </table> </li> </ol> <p>考虑证明 1, 2, 3。</p> <p><img src="/assets/img/blog_post/it/it-19.png" alt="it-19" width="50%"/></p> </li> </ul> <h4 id="33-熵速率及其应用">3.3 熵速率及其应用</h4> <p>回顾熵速率的定义， \(\begin{aligned} H_\infty(X) &amp; = \lim\limits_{n \to \infty} H_n(X)= \lim\limits_{n \to \infty} H(X_n|X_{n-1},X_{n-2}, \cdots, X_1) \newline &amp; \leq H(X_N \mid X_{N-1} X_{N-2} \cdots X_2 X_1) \newline &amp; \leq \cdots \leq H(X_2 \mid X_1) \leq H(X_2) \leq \log K \end{aligned}\)</p> <p>可以看到，熵速率 $H_\infty(X) = \lim\limits_{n \to \infty} H_n(X)$ 基本是小于单字符的熵值 $\log K$ 的。据此，我们定义</p> <ul> <li> <p>熵的相对率 $\eta=\frac{H_\infty(X)}{\log K}$，显然 $\eta \leq 1$。</p> </li> <li> <p>信源冗余度 $R = 1 - \eta$。</p> </li> </ul> <p><strong>熵速率的例子：</strong></p> <p><img src="/assets/img/blog_post/it/it-20.png" alt="it-20" width="50%"/></p> <h4 id="34-马尔可夫信源">3.4 马尔可夫信源</h4> <p>回顾定义：$m$ 阶的马尔可夫信源：</p> \[P(X_l|X_{l-1},X_{l-2},\cdots,X_0)=P(X_l|X_{l-1},X_{l-2},\cdots,X_{l-m})\] <table> <tbody> <tr> <td>马尔可夫信源具有一个有限的状态空间，可表示为 $x^m = x_{i_{l-1}}x_{i_{l-2}} \cdots x_{i_{l-m}} \in \mathcal{X}^m$，而其大小 $</td> <td>\mathcal{X}^m</td> <td>=K^m$。</td> </tr> </tbody> </table> <ul> <li> <p>马尔可夫信源计算熵速率</p> <p>熵速率是趋于无限时的平均熵，而这个无限一般是很难处理的。</p> <p>不过当信源满足马尔科夫的性质时，我们可以只关心那 $K^m$ 个状态来模拟无穷时的情况。</p> <p>例如，考虑这样一个二元一阶马尔可夫平稳信源的场景：</p> <p><img src="/assets/img/blog_post/it/it-21.png" alt="it-21" width="50%"/></p> <p>我们可以这样地计算其熵速率 $H_\infty$：</p> <p><img src="/assets/img/blog_post/it/it-22.png" alt="it-22" width="50%"/></p> <p>其中 $\mu_1$ 和 $\mu_2$ 可以利用马尔科夫链的稳态来算出。</p> </li> </ul> <hr/> <h2 id="chapter-2-信息的无损压缩">Chapter 2 信息的无损压缩</h2> <p>接下来进入编码部分。</p> <ul> <li> <p>信息传输模型</p> <p><img src="/assets/img/blog_post/it/it-23.png" alt="it-23" width="50%"/></p> </li> <li> <p>我们关心的编码问题是</p> <ol> <li> <p>构成描述信源的模型：随机变量序列或随机过程；</p> </li> <li> <p>计算信源的信息量，或者说信源的熵。</p> </li> </ol> </li> <li> <p>信源编码的目标：在代价最小的意义上来最有效地表示一个信源</p> <p><img src="/assets/img/blog_post/it/it-24.png" alt="it-24" width="50%"/></p> </li> </ul> <h3 id="lec-4-等长编码">Lec 4 等长编码</h3> <h4 id="41-引入离散无记忆信源-dms-的编码">4.1 引入：离散无记忆信源 (DMS) 的编码</h4> <p>考虑字符表 $\mathcal{A} = \{a_1,a_2,\cdots,a_K\}$，其概率分布 $\mathcal{P} = \{p_1,p_2,\cdots,p_K\}$。现在有长度为 $L$ 的消息序列 $u^L=\{u_1,u_2,\cdots,u_L\}$，而我们需要对其进行编码。对于 <strong>离散无记忆</strong> 的信源，$u_i$ 与 $u_j$ 的分布统计独立。</p> <p>考虑这样一种编码：编码字符表 $\mathcal{B} = \{b_1,b_2,\cdots,b_D\}$，编码长度为 $N$。显然，要实现无损编码，必须有（若无说明，接下来默认底数为 2）</p> \[D^N \ge K^L \ (N \ge \frac{L \log K}{\log D})\] <p>举例：</p> <p>$\mathcal{A} = \{0,1,2,3,\cdots,9\}, L=2$。等概。若编码字符表 $\mathcal{B}=\{0,1\}$，则 $N \ge 2 \log 10 \ge 7$。每个字符平均要 3.5 bit。</p> <h4 id="42-香农编码定理">4.2 香农编码定理</h4> <p>仍旧考虑 <strong>离散无记忆信源</strong>。</p> <p>我们回顾上式 $N \ge \frac{L \log K}{\log D}$。回忆熵的概念，记 $H(U)$ 是消息序列中单元素的熵，有 $H(U) \le \log K$。</p> <p>一个自然的想法是：我们是否能做到 $N = \frac{LH(U)}{\log D}$ 呢？</p> <ul> <li> <p>香农编码定理</p> <p>当 $N &gt; \frac{L(H(U)+\epsilon_L)}{\log D}$ 时，可以实现无损编码；</p> <p>当 $N &lt; \frac{L(H(U)-\epsilon_L)}{\log D}$ 时，不存在无损编码。</p> </li> <li> <p>香农编码定理的理解</p> <p>此处的「无损编码」指的是信源编码的错误概率可以 <strong>任意小</strong>，但不一定等于零。当 $L \to + \infty$ 时，上述定理才能得以体现，也才能实现香农编码。</p> <p>我们可以追加定义 <strong>编码速率</strong>：$R=\frac{N}{L} \log D$。香农编码定理指出，当消息序列长度 $L \to + \infty$ 时，存在某种编码，使得 $R \to H(U)$。</p> </li> <li> <p>香农编码定理的证明</p> <ol> <li> <p>渐进等分性质</p> <p>对于某个长度为 $L$ 的消息序列 $u^L=\{u_1,u_2,\cdots,u_L\}$，由于信源是离散无记忆的，其发生概率 $p(u^L)=\Pi_{i=1}^L p(u_i)$。</p> <p>同时，这个已知序列带来的 <strong>自信息</strong> 为 $I(u^L)=-\log p(u^L) = \sum_{i=1}^L I(u_i)$。</p> <p>定义随机变量 $I_L=\frac{1}{L} I(u^L) =\frac{1}{L}\sum_{i=1}^L I(u_i)$，其意义为消息序列的自信息对于单个元素的均值。</p> <p>根据概统相关知识，我们有</p> \[E(I_L)=E\\{I(u)\\}=H(U)\] \[D(I_L)=\frac{1}{L}D\\{I(u)\\}=\frac{\sigma_I^2}{L}\] <p>这里 $\sigma_I^2$ 是人为定义的，表示单个元素信息量的方差。再次强调，$H(U)$ 表示单元素的熵。</p> <table> <tbody> <tr> <td>根据 <strong>切比雪夫不等式</strong>，$P\{</td> <td>\xi-E(\xi)</td> <td>&gt;\epsilon\} \leq \frac{\operatorname{Var}(\xi)}{\epsilon^2}$。这里 $\epsilon$ 是人为指定的。</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>代入得到 $P\{</td> <td>I_L-H(U)</td> <td>&gt;\epsilon\} \leq \frac{\sigma_I^2}{L\epsilon^2}$。</td> </tr> </tbody> </table> <p>给定 $\epsilon$，当 $L$ 充分大，有 $\frac{\sigma_I^2}{L\epsilon^2} &lt; \epsilon$。</p> <p>所以，当 $L$ 足够大时，我们有</p> \[P\\{|I_L-H(U)|&gt;\epsilon\\} \leq \epsilon\] <p>或</p> \[P\\{|I_L-H(U)|&lt;\epsilon\\} \geq 1 - \epsilon\] <p>直观的理解是，当 $L$ 充分大时，$I_L$ 会逼近 $H(U)$。</p> </li> <li> <p>典型列</p> <p>令 $H(U)$ 为一个 DMS $\{ U,p(\cdot) \}$ 的熵，$\epsilon$ 为任意正数。称</p> \[A_\epsilon^{(L)}(U)= \left \\{u^L: \left | -\frac{1}{L} \log p \left(u^L \right) - H(U) \right| &lt; \epsilon \right \\} = \left \\{ u^L : \left |I_L-H(U) \right | &lt; \epsilon \right \\}\] <p>为给定 DMS 消息长度为 $L$ 的 $\epsilon$ 典型列集合。其中 $u^L\in U^L$。</p> <p>典型列具有以下性质：</p> <p><strong>【A - 渐进等分】</strong></p> <p>当 $L$ 足够大时，$P\{ u^L \in A_\epsilon^{(L)}(U) \} \geq 1 - \epsilon$。</p> <p><strong>【B - 数目计算】</strong></p> <p>前提结论，根据 $A_\epsilon^{(L)}(U)$ 的定义可以得出：</p> \[2^{-L(H(U)+\epsilon)} \leq p\left(u^L\right) \leq 2^{-L(H(U)-\epsilon)}, \text { if } u^L \in A_\epsilon^{(L)}(U)\] <p>进而可以推得：</p> \[(1-\epsilon) 2^{L(H(U)-\epsilon)} \leq\left|A_\epsilon^{(L)}(U)\right| \leq 2^{L(H(U)+\epsilon)}\] <p>左侧是因为 \(1 \geq \sum_{u^L \in A_\epsilon^{(L)}(U)} p\left(u^L\right) \geq \sum_{u^L \in A_\epsilon^{(L)}(U)} 2^{-L(H(U)+\epsilon)} =\left|A_\epsilon^{(L)}(U)\right| \cdot 2^{-L(H(U)+\epsilon)}\)</p> <p>所以 \(\left|A_\epsilon^{(L)}(U)\right| \leq 2^{L(H(U)+\epsilon)}\)</p> <p>右侧因为</p> \[1-\epsilon \leq \sum_{u^L \in A_\epsilon^{(L)}(U)} p\left(u^L\right) \leq \sum_{u^L \in A_\epsilon^{(L)}(U)} 2^{-L(H(U)-\epsilon)} =\left|A_\epsilon^{(L)}(U)\right| \cdot 2^{-L(H(U)-\epsilon)}\] <p>所以 \(\left|A_\epsilon^{(L)}(U)\right| \geq(1-\epsilon) 2^{L(H(U)-\epsilon)}\)</p> </li> <li> <p>最终推导</p> <p>回到我们的香农编码定理。其基本思想其实就是证明，当 $L \to +\infty$ 时，典型列基本占领了全部的 DMS，所以我们只需要对典型列进行编码（丢弃少数保大多数）。具体地：</p> <table> <tbody> <tr> <td>由于典型列的数目 $\left</td> <td>A_\epsilon^{(L)}(U)\right</td> <td>\leq 2^{L(H(U)+\epsilon)}$，所以当 $N &gt; \frac{L(H(U)+\epsilon_L)}{\log D}$ 时，我们一定有方法对所有典型列进行等长编码（像 $D^N \ge K^L$ 那样），而对所有的非典型列用统一的一个序列编码（例如全 D），当接收端接收到全 D 时，直接认为编码错误。</td> </tr> </tbody> </table> <p>此时错误概率即为 $p_e=p\left\{\hat{u}^L \neq u^L\right\}=p\left\{u^L \notin A_\epsilon^{(L)}(U)\right\}&lt;\epsilon$。由于当 $L \to +\infty$ 时，$\epsilon$ 也可以取得更小（见渐进等分）。所以我们有 $p_e = \epsilon \to 0 \ (L \to +\infty)$ —— 也就是先前所说的「渐进无差错编码」。</p> <p>逆定理的证明略去，基本思路就是使用 2B 中的另一侧结论。</p> </li> </ol> </li> </ul> <h3 id="lec-5-不等长编码">Lec 5 不等长编码</h3> <h4 id="51-引入不等长编码的优势">5.1 引入：不等长编码的优势</h4> <p>考虑 DMS $\{a_1,a_2,a_3\}$，概率密度为 $\{0.5,0.25,0.25\}$，$H(U)=1.5$。</p> <ul> <li> <p>若用等长编码，在 $L \to \infty$ 时才能达到最佳编码的效率（香农编码定理）。</p> </li> <li> <p>若用不等长编码，用 $ \{ 1,00,01\}$ 分别编码 $\{a_1,a_2,a_3\}$，编码速率 $1.5$ bit。和 $L$ 的长度无关。</p> </li> </ul> <p><em>不等长编码依然符合香农编码定理。</em></p> <h4 id="52-intro-不等长编码">5.2 Intro: 不等长编码</h4> <p>若无说明，$K$：消息集（字符集）大小；$L$：消息长度；$D$：编码集大小（一般为 2）；$n_1 \sim n_K$：单个字符编码后的长度，注意不是总长度。</p> <p><img src="/assets/img/blog_post/it/it-25.png" alt="it-25" width="70%"/></p> <p><strong>【唯一可译】</strong> 由于长度不确定，各字符之间没有「分隔符」。所以我们需要关注某段信息是否具有二义性。例如，假设有一个不唯一可译的编码 $\mathcal{B}$，其消息 $\{1001010\}$ 可能被译为 $\{100,1010\}$ 或 $\{1001,010\}$。</p> <p>形式化地讲，需要满足 <strong>非奇异性</strong> 和 <strong>可拓展性</strong>。假设编码方法可以视作函数 $\phi(x)$，其中 $x$ 是一个原始字符。非奇异性要求 $\phi(x) \neq \phi(y) \ (x \neq y)$；可扩展性要求 $\phi(x^{L_1}) \neq \phi(y^{L_2})$。</p> <p><strong>【即时可译】</strong> 接收端接收到一段消息时的中途，可能暂时还无法确定这个前缀的意义。这会产生「译码延时」。</p> <p>注意：「即时可译」是建立在「唯一可译」的基础上的！</p> <ul> <li> <p>唯一可译的判据：Sardinas &amp; Petterson 判据</p> <p>考虑如下的算法：设编码集为 $c$（在 5.1 中 $c=\{1,00,01\}$）。</p> <ol> <li> <p>初始化：令 $S_0=c$。</p> </li> <li> <p>迭代：用以下两种方法对 $S_0$ 进行迭代。大概就是枚举码字集 $c$，然后和 $S_{i-1}$ 进行 <strong>前缀匹配 / 反前缀匹配</strong>（注意不包含后缀匹配）得到 $S_i$。</p> <p><img src="/assets/img/blog_post/it/it-26.png" alt="it-26" width="70%"/></p> </li> <li> <p>判断：若存在 $S_i$ 使得 $S_i \cap S_0 \neq \varnothing$，则不具有唯一可译性质。并且：</p> <p>若 $S_1 = \varnothing$，则该码唯一可译且即时可译。此时，一个码中没有码字是其它码字的前缀，称该码为 <strong>异字头码（前缀码）</strong>。</p> <p>若 $S_n = \varnothing \ (n&gt;1)$，则该码唯一可译且译码延时有限。</p> </li> </ol> <p>来看一个例子：</p> <p><img src="/assets/img/blog_post/it/it-27.png" alt="it-27" width="90%"/></p> <p>对于 Sardinas &amp; Petterson 判据，一个 subcase 的感性证明是：</p> <p><img src="/assets/img/blog_post/it/it-28.png" alt="it-28" width="90%"/></p> </li> <li> <p>即时可译的 <strong>存在性</strong> 判据：Kraft 不等式</p> <p>Kraft 不等式：存在长度为 $n_1,n_2,\cdots,n_K$ 的 $D$ 元异字头码的充要条件是</p> \[\sum\limits_{k=1}^KD^{-n_k}\le 1\] <p>注意这里只给定了长度，没有给定具体的编码方式。</p> <p>首先，对于异字头码，若将其用树形表示，那么所有码字只出现在叶子上（一个码中没有码字是其它码字的前缀）。</p> <p><img src="/assets/img/blog_post/it/it-29.png" alt="it-29" width="90%"/></p> <p>不等式证明如下（注意证明里砍的是叶节点而不是全部子树节点）：</p> <p><img src="/assets/img/blog_post/it/it-30.png" alt="it-30" width="90%"/></p> </li> <li> <p>唯一可译码一定满足 Kraft 不等式</p> <p>证明：假设一个唯一可译码共对一共 $K$ 种消息进行译码，$x_i$ 被译为 $C(x_i) (1 \le i \le K)$。</p> <p>考虑</p> \[\begin{aligned} \left(\sum_{k=1}^K D^{-n_k}\right)^r &amp; =\left(\sum_{k_1=1}^K D^{-n_{k_1}}\right)\left(\sum_{k_2=1}^K D^{-n_{k_2}}\right) \cdots\left(\sum_{k_r=1}^K D^{-n_{k_r}}\right) \newline &amp; =\sum_{k_1=1}^K \sum_{k_2=1}^K \cdots \sum_{k_r=1}^K D^{-\left(n_{k_1}+n_{k_2}+\cdots+n_{k_r}\right)} \newline &amp; =\sum_{i=1}^{rn_{\max}} A_i D^{-i} \end{aligned}\] <p>其中 $A_i$ 是一种抽象的系数表示。细品上面的式子，会发现等式左侧的数学意义恰为【所有长度为 $r$ 的可能的原始消息】的多项式展开；那么对应地，$A_i$ 的意义则是所有长度为 $i$ 的【编码后消息】数目。由于唯一可译码的「可拓展性」，所以一定有 $A_i \le D^i$（若 $A_i &gt; D^i$，根据抽屉原理，一定存在两个不同的原始消息，它们映射到了同一个编码后消息上）。</p> <p>所以</p> \[\sum_{k=1}^K D^{-n_k} \leq \left ( \sum_{i=1}^{rn_{\max}} 1 \right)^{\frac{1}{r}} = (rn_{\max})^{\frac{1}{r}}=e^{\frac{1}{r}\ln (rn_{\max})}\] <p>当 $r \to \infty$，有 $\frac{1}{r}\ln r \to 0$，即上式在 $r \to \infty$ 时小于等于 $1$。</p> <p><strong>根据这一性质，对于任意的「唯一可译码」，一定存在一个同样编码长度的「异字头码」。这说明，如果一种码字方法唯一可译但是不即时可译，它总能够被优化！</strong></p> </li> <li> <p>不等长编码定理</p> <p>任何一个唯一可译码的平均码字长度必须满足 $\overline{n} \ge \frac{H(U)}{\log D}$，同时一定存在一个 $D$ 元唯一可译码，其平均长度满足 $\overline{n} \le \frac{H(U)}{\log D} + 1$。</p> <p><img src="/assets/img/blog_post/it/it-31.png" alt="it-31" width="80%"/></p> </li> </ul> <h4 id="53-huffman-编码">5.3 Huffman 编码</h4> <p>基本思路：对于概率分布</p> \[U \sim\left(\begin{array}{ccccc}a_1 &amp; a_2 &amp; \cdots &amp; a_{K-1} &amp; a_K \newline p_1 &amp; \geq p_2 &amp; \cdots &amp; \geq p_{K-1} &amp; \geq p_K\end{array}\right)\] <p>每次找 $p$ 最小的两个符号 $a_{K-1}, a_K$，赋予其 LSB 以 $0$ 和 $1$，然后将其合并。不断迭代此过程，直至概率分布集合中只剩下一个符号。例如</p> <p><img src="/assets/img/blog_post/it/it-32.png" alt="it-32" width="70%"/></p> <ul> <li> <p>Huffman 编码正确性理解</p> <ol> <li>对于给定信源，存在最佳唯一可译码（二元码），其最小概率的两个消息对应的码字等长，且长度最长，同时这两个码字的最后一位码元取值不同。</li> </ol> <p>证明略去。</p> <ol> <li>对辅助源 $U’$ 的最佳编码也是对原始源 $U$ 的最佳编码。</li> </ol> </li> <li> <p>D 元 Huffman 编码</p> <p>和二元的情形基本一致。</p> <p>唯一的区别是，若 $K=(D-1)i+1$，则每次均有 $D$ 个消息要合并，短标号充分利用；若 $K=(D-1)i+M$，则需要在最开始提前增补 $D-M$ 个概率为零的虚拟消息，使得短标号得到充分利用。一个例子如下。</p> <p><img src="/assets/img/blog_post/it/it-33.png" alt="it-33" width="70%"/></p> </li> </ul> <h4 id="54-shannon-编码">5.4 Shannon 编码</h4> <p>Shannon 编码并非最优，但它可以在一开始确定所有符号的码长，同时它也满足前缀码的性质。对于</p> \[U \sim\left(\begin{array}{ccccc}a_1 &amp; a_2 &amp; \cdots &amp; a_{K-1} &amp; a_K \newline p_1 &amp; \geq p_2 &amp; \cdots &amp; \geq p_{K-1} &amp; \geq p_K\end{array}\right)\] <p>记 $P_k=\sum\limits_{i=1}^{k-1}p_i \ (P_1=0)$，$P_k=0.c_1c_2\cdots c_{l_k}\cdots$（二进制展开）。其中 $l_k=\lceil \log \frac{1}{p_k} \rceil$</p> <p>那么 $a_k$ 的 Shannon 码字即为 $c_1c_2\cdots c_{l_k}$。</p> <p>举例（码字行是 Shannon 编码）：</p> <p><img src="/assets/img/blog_post/it/it-34.png" alt="it-34" width="70%"/></p> <ul> <li> <p>Shannon 码为前缀码的证明</p> <p>引理：如果把长度为 $l$ 的二进制码字 $z＝z_1z_2\cdots z_l$ 与一个区间</p> \[(0.z_1z_2\cdots z_l,0.z_1z_2\cdots z_l+\frac{1}{2^l}]\] <p>对应，则一个码是前缀码就等价于这些码字所对应的区间彼此不相交。证明略去。</p> <p>回到原命题，那么</p> <p><img src="/assets/img/blog_post/it/it-36.png" alt="it-36" width="50%"/></p> <p>其中 $[P_k]_{l_k}$ 的小数部分就是 $a_k$ 的编码。这表明 Shannon 码为前缀码。</p> </li> </ul> <h4 id="55-fano-编码">5.5 Fano 编码</h4> <p><img src="/assets/img/blog_post/it/it-35.png" alt="it-35" width="90%"/></p>]]></content><author><name></name></author><category term="CourseNotes"/><category term="Mathematics"/><summary type="html"><![CDATA[Information Theory Note (Part 1 of 2)]]></summary></entry><entry><title type="html">Information Theory Note (Part 2 of 2)</title><link href="https://sqrtyz.github.io/blog/2024/IT-NOTE-2/" rel="alternate" type="text/html" title="Information Theory Note (Part 2 of 2)"/><published>2024-01-01T12:00:00+00:00</published><updated>2024-01-01T12:00:00+00:00</updated><id>https://sqrtyz.github.io/blog/2024/IT-NOTE-2</id><content type="html" xml:base="https://sqrtyz.github.io/blog/2024/IT-NOTE-2/"><![CDATA[<h2 id="chapter-3-无损信息传输">Chapter 3 无损信息传输</h2> <ul> <li> <p>回顾信息传输模型</p> <p><img src="/assets/img/blog_post/it/it-23.png" alt="it-23" width="70%"/></p> </li> <li> <p>信道的抽象数学模型</p> <p><img src="/assets/img/blog_post/it/it-37.png" alt="it-37" width="70%"/></p> <p>其中 $W$ 可视为原始信息编码后的结果，$x^n$ 进入信道，$y^n$ 是接收方从信道中获得的信号，$\hat{W}$ 是接收方对信道信号的解读，它同时是对 $W$ 的估计。</p> </li> </ul> <h3 id="lec-6-信道容量">Lec 6 信道容量</h3> <p>信道容量定义为输出序列对不同输入序列所提供的最大互信息，即</p> \[C = \lim\limits_{n \to \infty} \frac{1}{n} \max\limits_{P(X^n)} \left[I(X_1X_2\cdots X_N;Y_1Y_2\cdots Y_N) \right]\] <p>注意 $\max$ 这里枚举的是不同的输入概率分布。</p> <h4 id="61-dmc-intro">6.1 DMC Intro</h4> <p>对于离散无记忆信道 (DMC, 定义见上)，$I(X_1X_2\cdots X_N;Y_1Y_2\cdots Y_N) \le \sum_{n=1}^N I(X_n;Y_n)$</p> <p>其中等号在输入为独立随机序列时达到。证明如下</p> <p><img src="/assets/img/blog_post/it/it-38.png" alt="it-38" width="60%"/></p> <p>（注意这些仅仅对 DMC 成立。特别地，当输入独立随机时，必有输出也独立随机，进而有 $H(Y)=\sum\limits_{i=1}^n H(Y_i)$ 的等号成立）</p> <p>因此，当输入独立随机时，有</p> \[C = \lim\limits_{n \to \infty} \frac{1}{n} \max\limits_{P(x^n)} \left[I(X_1X_2\cdots X_N;Y_1Y_2\cdots Y_N) \right] = \max\limits_{P(X)} I(X;Y)\] <p>这将大大简化接下来的讨论难度。</p> <h4 id="62-dmc-examples">6.2 DMC Examples</h4> <ul> <li> <p>无噪信道</p> <p><img src="/assets/img/blog_post/it/it-39.png" alt="it-39" width="80%"/></p> </li> <li> <p>无损信道</p> <p><img src="/assets/img/blog_post/it/it-40.png" alt="it-40" width="80%"/></p> </li> <li> <p>确定信道</p> <p><img src="/assets/img/blog_post/it/it-41.png" alt="it-41" width="80%"/></p> </li> <li> <p>无用信道</p> <p><img src="/assets/img/blog_post/it/it-42.png" alt="it-42" width="80%"/></p> </li> <li> <p>复制信道</p> <p><img src="/assets/img/blog_post/it/it-43.png" alt="it-43" width="80%"/></p> </li> <li> <p>二元对称信道 BSC</p> <p><img src="/assets/img/blog_post/it/it-44.png" alt="it-44" width="80%"/></p> </li> <li> <p>二元除删信道 BEC</p> <p><img src="/assets/img/blog_post/it/it-45.png" alt="it-45" width="80%"/></p> </li> </ul> <h4 id="63-信道的组合">6.3 信道的组合</h4> <ul> <li> <p>平行信道（积信道）</p> <p><img src="/assets/img/blog_post/it/it-46.png" alt="it-46" width="80%"/></p> </li> <li> <p>开关信道（和信道）</p> <p><img src="/assets/img/blog_post/it/it-47.png" alt="it-47" width="80%"/></p> <p>证明似乎有些复杂。</p> </li> <li> <p>级联信道</p> <p><img src="/assets/img/blog_post/it/it-48.png" alt="it-48" width="80%"/></p> </li> <li> <p>实例：两个对称信道的组合</p> <p>假设有两个对称信道</p> <p><img src="/assets/img/blog_post/it/it-49.png" alt="it-49" width="60%"/></p> <ol> <li> <p>积组合</p> <p><img src="/assets/img/blog_post/it/it-50.png" alt="it-50" width="80%"/></p> </li> <li> <p>和组合</p> <p><img src="/assets/img/blog_post/it/it-51.png" alt="it-51" width="80%"/></p> </li> <li> <p>级联组合</p> <p><img src="/assets/img/blog_post/it/it-52.png" alt="it-52" width="70%"/></p> </li> </ol> </li> </ul> <h3 id="lec-7-离散无记忆信道的容量定理">Lec 7 离散无记忆信道的容量定理</h3> <p>回顾之前所提及的，我们要求出某个信道的「容量」，即求 $C = \max\limits_{\{Q_k\}} I(X;Y)$。</p> <p>这里 $\{Q_k\}$ 描述的是概率空间。约束条件是 $Q_k \ge 0, \ \sum\limits_{k=0}^{K-1} Q_k=1$。</p> <h4 id="71-凸优化">7.1 凸优化</h4> <ul> <li> <p>函数为凸的条件：Hessian 矩阵半正定</p> \[H(x)=\left(\begin{array}{cccc} \frac{\partial^2 f(x)}{\partial x_1{ }^2} &amp; \frac{\partial^2 f(x)}{\partial x_1 \partial_2} &amp; \cdots &amp; \frac{\partial^2 f(x)}{\partial x_1 \partial x_K} \newline \frac{\partial^2 f(x)}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f(x)}{\partial x_2{ }^2} &amp; \cdots &amp; \frac{\partial^2 f(x)}{\partial x_2 \partial x_K} \newline \vdots &amp; \vdots &amp; \ddots &amp; \vdots \newline \frac{\partial^2 f(x)}{\partial x_K \partial x_1} &amp; \frac{\partial^2 f(x)}{\partial x_K \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f(x)}{\partial x_K{ }^2} \end{array}\right)\] </li> <li> <p>KKT 条件：取得最值的通用必要条件</p> <p>可以视作拉格朗日乘数法的拓展。拉格朗日乘数法解决的优化问题只有等号约束，而 KKT 条件加上了不等号约束。对于优化问题</p> <p>Minimize $f(x)$</p> <p>Subject to: $g_i(x) \leq 0, h_j(x)=0$</p> <p>则取得最值的必要条件是</p> \[\begin{aligned} &amp; \nabla f\left( x^* \right)+\sum_{i=1}^m \mu_i \nabla g_i\left( x^* \right)+\sum_{j=1}^l \lambda_j \nabla h_j\left( x^* \right)=0 \newline &amp; h_j\left( x^* \right)=0, \text { for all } j=1, \ldots, l \newline &amp; g_i\left( x^* \right) \leq 0, \text { for all } i=1, \ldots, m \newline &amp; \mu_i \geq 0, \text { for all } i=1, \ldots, m \newline &amp; \mu_i g_i\left( x^* \right)=0, \text { for all } i=1, \ldots, m \end{aligned}\] <p>前两条是拉格朗日乘数法也有的，后三条由不等式约束产生。</p> </li> <li> <p>概率空间情形的凸优化</p> <p>可以根据 KKT 条件，也可以通过数学直觉推断出概率空间情形的凸优化解条件。</p> <ol> <li> <p>非负空间的最值</p> <p>\(f'(x)=0, \forall x_k &gt; 0\) \(f'(x)&lt;0, \forall x_k = 0\)</p> </li> <li> <p>概率空间的最值</p> <p>\(f'(x)=\lambda, \forall x_k &gt; 0\) \(f'(x)&lt;\lambda, \forall x_k = 0\)</p> <p>其中 $\lambda$ 是拉格朗日乘数，其值由约束 $h(x)=\sum\limits_k x_k = 1$ 产生。</p> </li> </ol> </li> </ul> <h4 id="72-离散无记忆信道的容量定理">7.2 离散无记忆信道的容量定理</h4> <p>定理：概率分布 $\{Q_0,Q_1,\cdots,Q_{K-1}\}$ 达到概率转移矩阵 $P$ 的离散无记忆信道容量 $C$ 的充要条件为（等价于）：</p> <p>\(I(X=k;Y)=C, \forall Q_k &gt; 0\) \(I(X=k;Y)&lt;C, \forall Q_k = 0\)</p> <p>其中 $I(X=k;Y)$ 表示通过信道传送字符 $X = k$ 时，信道的输入与输出之间可获得的互信息的期望值。即</p> \[I(X=k ; Y)=\sum_{j=0}^{J-1} p(j \mid k) \left[I(y_j) - I(y_j \mid x_k) \right] = \sum_{j=0}^{J-1} p(j \mid k) \log \frac{p(j \mid k)}{p(j)}\] <p>不难发现，$I(X;Y)=\sum\limits_k Q_k I(X=k ; Y)$。</p> <p>回到原定理。我们其实是要在一个概率空间中找到 $I(X;Y)$ 的最值。考虑拉格朗日乘数法：</p> \[\begin{gathered} J\left(\left\\{Q_k\right\\}\right)=I(X ; Y)-\lambda\left(\sum_{k=0}^{K-1} Q_k\right)=\sum_{k=0}^{K-1} Q_k I(X=k ; Y)-\lambda\left(\sum_{k=0}^{K-1} Q_k - 1\right) \newline \newline \frac{\partial J\left(\left\\{Q_k\right\\}\right)}{\partial Q_k}\left\\{\begin{array}{l} =0, \forall Q_k&gt;0 \newline &lt;0, \forall Q_k=0 \end{array}\right. \end{gathered}\] <p>对 $Q_k$ 求导，得（可以证明第二项的值为 $1$，详见课件）</p> \[\begin{gathered} \frac{\partial J\left(\left\\{Q_k\right\\}\right)}{\partial Q_k}=I(X=k ; Y)+\sum_{l=0}^{K-1} Q_l \frac{\partial I(X=l ; Y)}{\partial Q_k}-\lambda \newline =I(X=k ; Y)-\lambda + 1 \end{gathered}\] <p>如果我们令 $C = \lambda - 1$，就可以得到定理内容：</p> \[\begin{gathered} I(X=k ; Y)=C, \forall Q_k&gt;0 \newline I(X=k ; Y)&lt;C, \forall Q_k=0 \end{gathered}\] <ul> <li> <p>定理的理解</p> <p>取到离散无记忆信道的容量的充要条件是对于好的 $I(X = k; Y)$，其值均相等，对于不好的 $I(X = k; Y)$，其值均为 $0$。在这种条件下，就有</p> \[C = I(X;Y) = \sum\limits_k Q_k I(X=k ; Y)\] </li> </ul> <h4 id="73-sp-case---对称离散无记忆信道">7.3 SP Case - 对称离散无记忆信道</h4> <p>离散无记忆信道的转移概率矩阵可表示为</p> \[\mathbf{P}=\{p(j \mid k)\}=\left[\begin{array}{cccc} p(0 \mid 0) &amp; p(1 \mid 0) &amp; \cdots &amp; p(J-1 \mid 0) \newline p(0 \mid 0) &amp; p(1 \mid 1) &amp; \cdots &amp; p(J-1 \mid 1) \newline \vdots &amp; \vdots &amp; \ddots &amp; \vdots \newline p(0 \mid K-1) &amp; p(1 \mid K-1) &amp; \cdots &amp; p(J-1 \mid K-1) \end{array}\right]\] <ul> <li> <p>若 $P$ 中每一行都是第一行的一个置换，则该信道关于输入对称。</p> </li> <li> <p>若 $P$ 中每一列都是第一列的一个置换，则该信道关于输出对称。</p> </li> <li> <p>若一个信道既关于输入对称，又关于输出对称，则该信道是 <strong>对称的</strong>。</p> \[\begin{aligned} P &amp; =\left(\begin{array}{llll} 0.2 &amp; 0.1 &amp; 0.4 &amp; 0.3 \newline 0.3 &amp; 0.1 &amp; 0.4 &amp; 0.2 \newline 0.2 &amp; 0.4 &amp; 0.1 &amp; 0.3 \newline 0.3 &amp; 0.4 &amp; 0.1 &amp; 0.2 \end{array}\right) \end{aligned}\] </li> <li> <p>若一个信道可以按列划分，得到若干个子信道，若划分出的所有子信道均是对称的，则称该信道是准对称的。</p> \[\begin{aligned} \mathbf{P} &amp; =\left(\begin{array}{lll} 0.8 &amp; 0.1 &amp; 0.1 \newline 0.1 &amp; 0.1 &amp; 0.8 \end{array}\right) \end{aligned}\] </li> </ul> <p>可以证明，<strong>达到准对称离散无记忆信道容量的输入分布为均匀分布</strong>。基本思路是当 $Q_k = \frac{1}{K}$ 时可以推出 $I(X=k;Y)$ 都相等。</p> <p>根据定义，若信道关于输入对称，则（其中 $k$ 任取）：</p> \[I(X;Y)=H(Y) - H(Y|X) = H(Y) + \sum\limits_{j=0}^{J-1} p(j|k) \log p(j|k)\] <p>通过上述结论，我们可以获得关于信道容量在特殊情形下的性质：</p> <ol> <li> <p>若信道关于输入对称，则（其中 $k$ 任取）：</p> \[C \leq \log J + \sum\limits_{j=0}^{J-1} p(j|k) \log p(j|k)\] </li> <li> <p>若信道同时关于输入和输出对称（即信道对称），则有 $H(Y) = \log J$，同时再根据上面均匀分布那个结论，于是（其中 $k$ 任取）：</p> \[C = \log J + \sum\limits_{j=0}^{J-1} p(j|k) \log p(j|k)\] </li> </ol> <ul> <li> <p>Examples</p> <ul> <li> <p>K 元对称信道的容量：直接用上面第二个公式就可以算。</p> <p><img src="/assets/img/blog_post/it/it-53.png" alt="it-53" width="70%"/></p> </li> <li> <p>除删信道（BEC）：由于 BEC 是准对称的，所以当输入等概时取到信道容量。</p> <p><img src="/assets/img/blog_post/it/it-54.png" alt="it-54" width="70%"/></p> </li> <li> <p>模 K 加法信道</p> <p><img src="/assets/img/blog_post/it/it-55.png" alt="it-55" width="70%"/></p> </li> </ul> </li> </ul> <h4 id="74-general-case---转移概率矩阵可逆信道">7.4 General Case - 转移概率矩阵可逆信道</h4> <p>对称信道由于均匀分布的那个结论所以方便计算。考虑更一般的情况，给定矩阵 $P$，如何求出取到信道容量的 $\{Q_k\}$ 分布和信道容量 $C$？</p> <p>如果 $P$ 可逆并且假设 $Q_k &gt; 0$，这个问题是可解的：</p> <p><img src="/assets/img/blog_post/it/it-56.png" alt="it-56" width="80%"/></p> <p>由此线性方程解出 $\beta_j$。</p> <p>注意到 $\sum\limits_{j=0}^{J-1} w_j = 1, w_j = 2^{\beta_j-C}$，所以 $C = \log (\sum\limits_{j=0}^{J-1} 2^{\beta_j})$。</p> <p>再根据 $C$ 和 $\beta_j$，回过头来解 $w_j$ 以及 $Q_i$。</p> <ul> <li>课件上有例子。</li> </ul> <h3 id="lec-8-离散无记忆信道的编码定理">Lec 8 离散无记忆信道的编码定理</h3> <h3 id="lec-9-加性高斯噪声awgn信道">Lec 9 加性高斯噪声（AWGN）信道</h3>]]></content><author><name></name></author><category term="CourseNotes"/><category term="Mathematics"/><summary type="html"><![CDATA[Information Theory Note (Part 2 of 2)]]></summary></entry></feed>